---
title: "Episode 1: David Cramer, creator of Sentry"
publishDate: 2020-06-15T10:01-07:00
tags: [podcast]
slug: david-cramer
published: false
---

<!-- START AUDIO -->
<audio className="object-center" src="https://www.buzzsprout.com/1097978/4078679-david-cramer-creator-of-sentry.mp3" controls={true} preload="auto"></audio>
<!-- END AUDIO -->


<!-- START GUESTS -->
<span>
David Cramer, Beyang Liu
</span>
<!-- END GUESTS -->

<!-- START SUMMARY -->
[David Cramer](https://twitter.com/zeeg) talks about creating [Sentry](https://sentry.io/welcome?referrer=sourcegraph-podcast) as an open-source side project, maintaining it while working full-time at Dropbox, and ultimately growing it into one of today's leading application error monitoring tools. We chat about the emergence of new computing platforms, his thoughts on what's truly new and what's just marketing-speak for old ideas, and how he sees the landscape of observability and monitoring tools evolving in the future.
<!-- END SUMMARY -->

<!-- START SHOWNOTES -->
Follow David on Twitter: [@zeeg](https://twitter.com/zeeg)

Sentry: https://sentry.io/, https://twitter.com/getsentry

IRC: https://en.wikipedia.org/wiki/Internet_Relay_Chat

mIRC: https://www.mirc.com/

Logging tools: Splunk (https://www.splunk.com), Kibana (https://www.elastic.co/kibana) from Elastic (https://www.elastic.co/)

Data Dog: https://www.datadoghq.com

Application Performance Monitoring (APM): https://www.gartner.com/reviews/market/application-performance-monitoring

Software Development Lifecycle (SDLC): https://www.tutorialspoint.com/sdlc/sdlc_overview.htm

Facebook's Scuba (internal performance monitoring tool): https://research.fb.com/wp-content/uploads/2016/11/scuba-diving-into-data-at-facebook.pdf, https://www.facebook.com/notes/facebook-engineering/under-the-hood-data-diving-with-scuba/10150599692628920/

Observability: https://thenewstack.io/observability-a-3-year-retrospective/

OpenTracing: https://opentracing.io/ 

OpenTelemetry: https://opentelemetry.io/

Distributed tracing: https://opentracing.io/docs/overview/what-is-tracing/

BDFL: https://en.wikipedia.org/wiki/Benevolent_dictator_for_life

Kubernetes: https://kubernetes.io/

Chef: https://www.chef.io/

Puppet: https://puppet.com/

BSD license: https://opensource.org/licenses/BSD-2-Clause

BSL (Business Source License): https://mariadb.com/bsl11/ 

Switching Sentry from BSD to BSL: https://blog.sentry.io/2019/11/06/relicensing-sentry

Django web framework: https://www.djangoproject.com/

django-db-log: https://github.com/dcramer/django-db-log

Monoliths, Microservices, Service-Oriented Architecture (SOA), Serverless: https://rubygarage.org/blog/monolith-soa-microservices-serverless

"Test in production" vs. "Don't test in production": https://opensource.com/article/17/8/testing-production

Blue-green deployment: https://martinfowler.com/bliki/BlueGreenDeployment.html

Five Whys: https://en.wikipedia.org/wiki/Five_whys 

GitHub Actions: https://github.com/features/actions
<!-- END SHOWNOTES -->

<!-- START TRANSCRIPT -->
*This transcript was generated using auto-transcription software.*


**Beyang:** All right. I'm here with David Cramer, former engineer at Dropbox, and now founder and CTO of Sentry, an open source tool for monitoring and resolving errors in production. David, welcome to the show.

**David:** Hey, thanks for having me happy to be here today.

**Beyang:** So to kind of kick things off,  what's your  quick life story as an engineer, starting with how you first got into programming.

**David:** So I'm very much the stereotypical self-taught. I think the first thing that I really did was there used to be this thing and I say used to be because it's not really well known these days called a IRC and specifically there's this windows client for it called MIRC, which had the most terrible scripting language you can possibly imagine.
And so I just started writing scripts while I'm chatting on the internet. I don't even remember what half of them did these days. The other half is probably not stuff you should, you should do as a professional, I would say. but, I don't know. It kind of like, it got me interested in, I could build things.
Right. And then sort of in tandem, I was, I was a big gamer at that age, I think is a lot of kids. And I found that you could, you know, Or rather I found you could engage a lot of folks by sort of building gaming. Like you could basically take your hobby and merge it with this other hobby. And like, what I did was I ended up building like gaming databases.
So, I think the first significant one I did was for world of Warcraft, but they said like, I data mined a lot of the code or the details of the game and publish them on the internet. And this is right when wow was coming out and getting popular and stuff. And I think that was like the first. Real endeavor I had where I'm like, Oh wow, there's actually something serious here that I can do.
That's actually really interesting and fun versus I just build a silly script or something. and then, you know, you kind of just continue that path and one thing leads to another.

**Beyang:**  How did you end up at Dropbox?

**David:** So yeah. I'm from the Midwest originally from Nebraska. And when I started doing this gaming stuff, which is when I was like 19 or something, I actually, I took a job. I don't know if it was legally allowed to be a job, but I took a job with a company that was like, they were, it was a bunch of kids.
We're all the same age, living in Germany. And we were basically building one of these world of Warcraft websites, one of these databases and a company's called curse. it's now part of Twitch, which I guess is part of what Amazon, I don't know, just once Nikita any other, but, and that actually, so that took me to Germany for a little bit.
I worked with that company a couple of years and there was only like five of us at the time. And then it took me to San Francisco. And so I did that eventually that's that company went to work with one of my buddies left San Francisco. Realized life was not nearly as interesting outside of SF, especially if you're really into software at the time.
And, you know, I came back, worked for another tech company called discuss, which isn't really around much these days, but it's, you know, big internet comments provider and did that for a while eventually decided. And that's also where I started Sentry, formerly, And then decided it was time for something else.
And I kind of limited my options of the kind of job I wanted and it was based on what I enjoyed doing. And that was like, I enjoyed doing things that have like high reach, so kind of interesting scale problems. And I just wanted to work with Python, the programming language. And so I was basically like, well, I can join Instagram or I can join Dropbox.
And one of them requires me to commute to South Bay. So, so Dropbox was a good choice for that.

**Beyang:** Awesome. Awesome. and you know, I want to dive into kind of the backstory of Sentry a little bit, but before we get into that, I wanna first describe to our audience what Sentry is. So, you know, if you're describing Sentry to an engineer who has never heard of it before, what is it.

**David:** So I probably have an infinite number of descriptors for it. Like the way I usually try to reason about it is that's kind of a way to take it away from engineering first off. But yeah. You load up the Uber app, it crashes. What do you do as a, as a user? Well, personally, I would just love Lyft because I have no brand loyalty.
It doesn't really matter. And that's actually pretty common. Right. And so when you take that in mind, that's the problem we're solving for that's the reality of the world, right? And so we're like, okay, like the advantage of a company in that situation is to be able to respond to those customers, like issues very, very quickly.
So what we do is we collect all that information about that crash or other application errors. And we send that to the engineering team that is actually responsible for that application. So it really helps them diagnose and, and hopefully fix errors, very quickly. I think the classic they now is, if somebody knows what Sentry is and they experienced an era in the world, they're just like calling out the company.
It's like, Hey, are you using Sentry? Like, why aren't you fixing your bugs kind of thing? So I think it implicitly suggests that it's a proactive way for software teams to actually resolve their issues, which is true. But that's still up to the software team at the end of the day.

**Beyang:** Yeah, it makes sense. So w when you say, you know, the, you know, the Uber app, if 
they're using a Sentry, they'll 
kind of send the era's over and their development team is able to kind of dig into those. Does that require kind of instrumenting that application with some 
sort of a Sentry clients at 
agent, or does it do smart things to kind of automatically you figure out what to do?

**David:** Yeah, so we really try for a frictionless process. So I I'm the type of. Builder that is very pragmatic. I think it's interesting to solve interesting problems, just like anybody, but frankly, I'm super lazy. And I just want to like get to the, like the cleanest, fastest solution I can. And that's the same for like when we build something for our customers.
So it's like for Sentry, it's very much like you install our dependency. You tell us the API key, which we give you. And then most of the time it works from there. There's a lot of advanced stuff you can do that requires you to put in effort. But for the most part, 80% of the value is just out of the box.
You don't have to do anything. That's actually been one of our big selling points for a very long time. and that that's kind of the same for every device. It gets a little bit trickier. You know, if you're saying writing compiled code or something seriously complex, you have to set up some other processes.
But for the most part, it works the same.

**Beyang:** Cool. I feel like laziness is almost like a, like a key developer value. It's it's good to be lazy in a lot of cases.

**David:** I think it's especially good if you're building productivity or tooling or you're sort of a product owner, because it's gonna hopefully get you to like the best solution you can with the least amount of costs.

**Beyang:** Yeah, just, just the essentials. 

**David:** Yeah. 

**Beyang:** Cool. And kind of taking a step back, you know, nowadays there's, there's a whole kind of landscape of, production monitoring tools, you know, things that help people diagnose errors, in deployment environments. can you kind of give us your view of that landscape and where Sentry fits in all that?

**David:** Yep. So I think there's a lot of ways to slice it, but the simplest way is there's sort of historical solutions. I bucket them into a few categories. The first would be logging. So you can think of that, like a Splunk or cabana, but pretty well known to folks. A second would be sort of this monitoring persona, which is.
You know, graphs at the end of the day, it's usually graphs monitoring your system metrics. That's Datadog would be the market leader. and then the third is what we would describe as an APM vendor, which would be new Relic. And the APM vendors are a little fuzzy cause they actually try to do everything these days.
But the core of what they started as was, I will tell you why your application is slow, which is the value add they originally gave you, right. That is kind of changed over the years. Cause like you'll note, I didn't say anything about air monitoring in there. So. You know, once upon a time and that kind of all works and people just dealt with the fact that it wasn't ideal.
And I think a lot of the changes over the years from how we developed software, sort of forced us to think about like, are these tools solving problems? And then, you know, the air monitoring, I wouldn't call it a category, but are monitoring functionality the way Sentry provides it, you know, which is.
Quite drastically different than logs. that's become more of a necessity when we've had a lot more front ends. So mobile browser, desktop applications that really need this rich monitoring. And on top of that, like sort of the, the breadth of the internet, and the depth, I guess, of an individual property has gotten much bigger.
So you end up with a lot more data, a lot more errors, a lot more customers. And so it just gets harder to reason about all the data. So, so kind of like, I think there's this new wave of things. So that, that was the old style, right? APM, all this other stuff. And we sort of think the new wave. It looks so much similar to the old way, but the difference I would say now is there's application monitoring.
You don't get that confused with APM, and then there was systems monitoring. And so systems you can think of is that an as infrastructure monitoring at the end of the day,  it's easiest to say, like, if I am running the platform layer, that is I'm building the layer that lets you. Ship your business logic.
I need systems monitoring. I'm dealing with the servers. I have CPS, I have discs. I need to rotate disc. I need to do all that stuff. Right. All that makes sense. If I'm building a business layer and the business logic, and especially when you think about serverless and these kind of paradigms, I don't care at all about that platform there.
I only care about it when you force me to care about it, which should be never at the end of the day. And so we think there's  a solution that's needed to really focus in on that, to focus in on this idea that you don't control the machine. And so what's the relevant information to surface.
And so that's really what we, what we say we're doing what we're trying to do, but like one version of that is air monitoring. And frankly, I would tell you the first version of that is air monitoring because it goes super deep and the way we do it, not only does it go really deep, but it's tightly coupled to the commit graph and the source code, which is really all you can control as a developer.
And so we think there's a lot more concern, so address there, but that's fundamentally how I see the landscape. And it's like, we really just say, you know, we're building something for application developers, which. You know, that's a little bit of a spiel. Like it's not entirely truthful of course. but you can kind of get the idea and the cleanest separation is if you say, well, we're building something for front end developers because people historically have thought of them as a, as a different persona or they are.
But like so much of our business logic is on the front end these days, you can no longer ignore it. So it's a, it's a way that we sent her to the gravity around kind of what we think is most important. And frankly, a lot of the, like the infrastructure monitoring tools they're really mature and the really, really good.
But they don't solve the rest of the problem. So that's kind of how I see it. And it's just those two, scopes in the landscape.

**Beyang:** yeah, that also makes sense. The focus on front end developers is interesting because, you know, when you think about traditionally the types of people who are digging into errors and production, it's like the opposite of those folks, right? The, you know, very artsy backendy folks.

**David:** Yep. And I think it's a, it was like a necessity. So I don't know if you've ever worked at a company like this, but for sure Dropbox was like this. If you wanted to know about problems in production, you're certainly not getting access to the server to go look at logs. Right. And frankly, logs are actually pretty sensitive these days.
Right. Especially with things like GDPR. So you're probably just not getting access period. And, you know, Dropbox is a little bit ahead of the curve. Just like every, you know, giant tech company has been, they had their own sort of Sentry, like thing internally. Now it wasn't nearly as good as Sentry. And I'm not saying that just because I built Sentry, but they'll tell you that too.
but they knew that they needed something like that. Right. And big companies recognize that problem. And so that's kind of how we thought about it. Ultimately.

**Beyang:** Yeah, that makes sense. Yeah. As a front end developer going to Sentry, like what, what kind of data am I looking at? Like what does that interface look like? Is it, am I just kind of doing like open-ended data exploration on some like SQL table that I have,  with like pretty graphs?
Or is it, is it something else?

**David:** Yeah, so that's actually, in our case, we're very specific and intentional that we say we're trying to give you answers. Not. You know, search tools. So we're not, we're not trying to let you go, you know, exploring caves. We just want to say that's where the treasure is and here's the zip line, right. To it kind of thing.
and so what we give you is as much as we possibly can, which again, that's a little bit of a gray area these days, especially privacy controls, but the baseline is we give you a stack trace, which most engineers should understand. but it's just like sort of the program instructions that were about invalid.
We do that in sort of specialized ways though, which is important. So in Java scripts, yeah, just Java script code, it looks like a normal sex race in compiled code. It's very different than a normal stack trace. but also when you go to like cross language, we actually blend those together as well. So for example, if you're using react native on mobile, we'll actually give you the JavaScript and the iOS stack trace sort of merged together.
And so that's, that's just one minor example of something we do that like makes it easier for a human to understand what's going on. so we take that and then we actually, not only did we give you sort of that rich view, but we give you surrounding source code, which means you don't have to jump to an editor or to get hub or something else to understand what's going on.
well often in some languages give you things like context, locals, which are basically variables that are defined during a, that exception, which is hugely valuable for debugging because that's your inputs at the end of the day. And then we'll try to give you a little bit of sort of. user behavior, but pie hole, please don't ban us again, but we give user behavior in the sense of like, here's sort of the steps that led up to this book, right?
so it might be the person clicked these three elements or something, or they navigated from this URL to this URL, to this URL and that trigger this book. And that's actually really useful and JavaScript, but actually isn't useful at all in other languages. So we actually have taken a stance of like, let's specialize a little bit language by language, cause it's is actually different.
And each of those. and then we allow you to send whatever else is helpful. So for Sentry, for example, we sent a lot of information about like the kind of customer. So that might be like we say, well, this is a super important customer, or it's a free customer or. I'm trying to think, what else, what else we can do there.
But we also send like diagnostic information. Like this is the device that happened on, this is the operating system. This is the browser name, things like that. Right. We used to famously tell folks, you no longer have to guess if it's internet Explorer, that's broken now, you know, it's internet Explorer, which was funnier when people still use internet Explorer.
I knew that what that meant, but, but yeah, so it's really about like, can we just. Get you the right answer instead of you having to ask more questions, which for the most part we can these days.

**Beyang:** So it sounds like, you know, that there's some kind of instrumentation monitoring tools that take the approach of like, Hey, we're just going to give you a bunch of key metrics like that are derived from the application layer of the systems layer. And then you're supposed to go and figure out how to piece that together.
It sounds like you're not doing that. You're kind of. Really designing for this, a front end developer persona first and foremost, like if you were in a front end developer shoes, what are all the pieces of information that you would want access to when you go, diving into some production issues? Is, is that right?

**David:** Yeah, that's a good way to think about it. We basically just say, if you can't change the machine, what's the root cause. If you're out of memory, you can't add memory. How do you fix it? Well, you look at the code that caused you to run out of memory or the change in the code that caused that behavior to happen.
Right? So we actually say our goal and we don't do this all the time and it's still, it's, it's a really hard problem. But our goal is to say root cause is to commit the commit that created this issue at the end of the day. And that's, that's true for 95% of failures at the end. Like yeah, you'll have incidents where say AWS goes down and that affects your service, but that's not really what we're optimizing around.
We're optimizing around velocity of, of, I guess shipping new software.

**Beyang:** Yeah. Makes sense. Are there other tools that you see people using Sentry in conjunction with, or that you would recommend, you know, deploying alongside Sentry?

**David:** I think many. So the ecosystem these days, or rather a developers world is very complex. Right? Like you yourselves are sort of what we described as like an adjacent tool. And, and we always thought about it. there's a lot of stuff that can play. Well, I guess in an ecosystem it can make a developer's life better, which usually just translates to efficiency.
Right? I think the four core pillars of that are, and we sort of look at like, what's the old style SDLC software development life cycle, which I didn't know what that meant by the way, before four years ago. but we look at that and we're like, Like what's a simple version. Yeah. Yeah. So we're like, well, okay, what you do as a developer is you write code.
So you develop, you test the code, which is CEI most of the time, these days, right. You release the code and then you need to monitor the code. And there's a lot of different paradigms of that. Some people call, monitor, learn, which would be more like a product analytics angle. But we just think about those forums where like, okay, Sentry is the solution to monitor it.
But we're not a solution for any of the rest of it. Right. And so there's all these other adjacent tools that I think make a ton of sense there. And, and, you know, things like source graph certainly help, the speed of development, like to help much earlier in the life cycle. We helped much later. but we always kind of say like, we, we picture this like slot machine kind of thing for visual and you, you spin the wheel and Sentry is always going to be a solution for monitoring.
You don't need anything else, but you can swap out the rest of the components. So we're actually a big believers that the ecosystem matters a lot because one company can't solve all the problems. But we also believe that we can solve all of the monitoring problems for an application. We don't yet, but we will over time.

**Beyang:** Does that make sense? you know, what do you make of, you know, you mentioned log aggregators. there's also things like promethiwhich give you kind of like time series overview of like key metrics there's distributed tracers. are those all kinds of tools that you eventually want to, bring kind of under the umbrella of the Sentry use case? Or are any of them kinda like outside of, of your eventual scope?

**David:** you might call me an anti thought leader. I am not on the bandwagon of observability. I'm not on the bandwagon of distributed tracing. I believe they're all just marketing shims. but I will say that Sentry has implemented distributing Traci for its customers for a new performance product.
And it looks wildly different than anybody else's product. And why that is, is because we're very focused on what the output is. And I will also tell you that we have metrics that you can alert on and we don't collect any metrics. And so what Sentry has done, and this is an impossible problem to solve.
So this will certainly not be our fault. A forever solution, but we basically suck in a ton of events in the most abstract way. Just imagine we suck in a lot of events. Some of them are ours. Some of them are what we call transactions, which are a segment of a trace, but it's a request response life cycle.
we pipe those into the system and then we extrapolate from there we extrapolate. Is this a problem? Is it a new era? Is it a unique air? we extrapolate, is it slow? Which is just the metric that's accumulated from all those together. things like that. And so, I'm a big believer in that model. unfortunately like.
If you just can imagine the amount of data in the world that it doesn't scale, of course, but that's kind of how we thought about it. So we will serve those things. I don't know about logs. I think logs have multiple uses. but I think traces in particular are just a means to an end. Like the way I described traces, the most folks is open, open telemetry, which is what the format's called.
Now. It's just an open source version of new Relic schema. Ultimately that's the, that would be my intention behind it. It's not some new kind of problem in the world. And so we've taken that idea because it's really good work. And I think the tracing products, they've got a lot of smart people behind, but we've taken that.
And we said, the product that people need is new Relic. The data might come from Tracy, but the product output looks more like new Relic. And so that's what we're building. there's some advanced questions you can answer by using like end to end traces. But for the most part, you're a mobile developer.
You're not looking at what's going on way down the stack in the database, right? Like you have no idea what that even means you just need to know is my mobile app performing well. And so that's like a really important lens we put on it, but I, to circle back to logging, I think that's an interesting one because.
Logs, actually the amount to a few things. One they're like this duct tape solution for any problem you have, like, if you look at elastic, they're just like put everything in a log in or spunk, probably the same thing and you can make metrics exist and you can aggregate things together and do all this crazy stuff, which is not a super effective solution, but.
We basically say logs are for audit trails. Like first and foremost, it's for compliance and it's for security. You must have that stuff. It's not a, it's not an opinion. It's not a discussion point. That's like a mandatory requirement for all organizations. You can't change that. Right. But then there's also this idea of logs for debugging.
And that's really where it gets interesting because technically speaking Sentry collects logs with its errors. We call them breadcrumbs, just like user click, this user click this that's just a log at the end of the day. And so we thought a lot about, and we frankly we'll probably build it, just allowing developers to send us logs as well, because it's very helpful in the debugging process.
But I think the challenge is, and rightfully so, nobody wants to pay, you know, duplicate fees for, for all of this stuff. Right. So if we're collecting logs and they're sending them to say Datadog and Splunk and all these other things, they're not going to be super thrilled about all the money they're just throwing away for no reason.
So I think that's a tricky area yet, but I do think tracing. It's just, you know, it's a means to an end more than it is a different product.

**Beyang:** Got it. That makes sense. Can I, can I get you to talk more about, observability, cause you know, full disclosure, another person we're going to have on the show is charity majors, of honeycomb. And I think they, they basically coined the term. so, you know, I would love to get your kind of candid thoughts if you're, if you're willing to share, on, on that kind of, idea as, as a movement and, the issues that you can see with it.

**David:** I would say you've never had to force somebody to do something that's very valuable for them. Maybe never is the wrong word there. And this idea that we're changing, what monitoring is. I don't think it's true at all. And so I'll give you an example. If you collect traces and you do no work, so say you put them in there by default, right?
And that's the idea of observability, is it exists? And then you can go ask questions. Well, all your data is useless. You still have to go add new instrumentation and make it more useful. And that completely breaks the idea that we're doing anything different than we ever did before. We're still reacting to problems and then adding additional telemetry at the end of the day, it's just the reality of the world.
Now you could say, well, one of the things we're enabling, because honeycomb is based on the concept of snuba or scuba, sorry. It's is our internal version scuba from Facebook, which every big company has a scuba. Right? And we now have a skew ourselves, and that model is really good, but that's just an infrastructure service at the end of the day.
It's just a very fast log search is the way I think about it. And that's a really powerful thing. That if you said that was observability, just being able to completely just to like 100%, just the side of ask questions, your data. That's great. I, I truly believe in that, but observability to me, and a lot of these things you see is just marketing and we've never been great at marketing, which is probably why we don't do any of those things, but we've also never needed it.
Like we don't really have to convince developers that air monitoring is valuable. We didn't even have a word for it for a long time ago. Like, we're just like, I know we, we aggregate exceptions or something. Right. And I think it's just, I don't see what people are doing is any different than what they were doing 20 years ago, ultimately.
And that's my issue with it. And it's the same with APM. Like we're so we're trying to solve the same problems that new Relic solved 10, 15 years ago, whenever it was born right now, they don't solve them that well, these days the solutions were still really good ideas. And we're just trying to like, make a better version of that really good idea.
And that's where I think people. Because it's, it's better to be different than it is to be, you know, the same or similar. And I think people are too focused on that and I just don't care about that. So I'm just like, I dunno, we're kind of building APM at the end of the day. It's the same thing. It's always been, it's like a category of stuff that sort of does these things and observability is just monitoring at the end of the day and, you know, and that's kinda my like, grab, so that is, I don't care about talking about it.
I'd rather just be building a great product for people to use and whatever you want to call it, you can call it. but, but that's where I lie.

**Beyang:** Yeah, that makes sense. And you said something and I just want to kinda like, repeat it back to you just to kind of, see if you agree with this. Like, I kind of got the sense that you were, your impression of observability is, It's trying to say that like, Hey, there's a, we have this completely new way of thinking about telemetry and instrumentation, basically like, you know, send every single event you could ever care about a tour service.
And so it's all accessible. You never have to worry about, you know, having forgotten to instrument something have to go back and add that piece of, instrumentation late, later was just this giant, you know, infinitely wide data blob, which you can kind of explore at your. leisure. And what you're saying is, that's kind of a pipe dream.
you're always going to add like some amount of instrumentation. There's always going to be kind of a shortcoming in, in what you're able to collect. And then the process is just like, you know, add the instrumentation that, you know, you need now. And then at some point it's gonna fall short and then go back and add more instrumentation later to get that data into, you know, whatever production dashboard it is you're using to debug those issues.
Is that about

**David:** very much how I feel about it. I will say the. The improvement we've gotten as an industry is the old way to add instrumentation by default was logs, right? Very unstructured. It was just human texts at the end of the day. And we've at least improved upon that where a lot of people do like Jason based logging such as key values, right.
Which is valuable of course. And tracing being built into libraries is actually very valuable because now we actually have real annotations. Now, the problem is. If their annotations, aren't good. You're still back in the starting point where it's not instrumented well now, so I just think it's an unsolvable problem and you have to give people the right tools.
And so I think the tech that everybody's building is really good. And, you know, we use click house, which is open source. So you can think of that as like an open source in a very naive way. It's open source honeycomb or opensource, scuba, or something like that. that tech is super powerful. Like we've replaced our entire logging infrastructure with click house at this point.
And we can ask like real time questions on it, which is great, but we still have to record the right sort of preemptive answers to those real time questions in it at the end of the day. And that's, that's where that falls down. but it's still a good iteration on technology. And so I think that's important.

**Beyang:**  you mentioned, that kind of the fundamental problem that you're trying to solve is kind of the same one that, the new relics and the Datadog's of the world are going after. why do you think it is that,  they've been unable to effectively solve that problem.

**David:** So, I guess my, I don't want to say arrogant, but my like real view of the situation is a lot of people build stuff for themselves. And that's no different than me, like Sentry was just me solving my own problem. I think the difference for me, and a lot of other folks is I know infrastructure, but I'm not just an infrastructure person.
I'm very much full-stack and I like building the end user experience. Right. And so we quickly biased towards like, you know, we actually want this to be about the end user, the customer versus we're building another systems monitoring tool and that's fine that people do that. But what you'll see is a lot of folks that are building new generations of technology.
They end up being very biased and they're just solving infrastructure monitoring, like with another flavor of the week kind of thing. And that's probably not giving enough credit, but, but I think that's the problem. So we actually, so we're launching our performance and in July and we set JavaScript first, if we can't solve JavaScript, it doesn't, it doesn't happen because that's the most important language in the world right now.
And that's not even subjective. and. It's also much harder to solve for than say Python. Like we solve Python in like one week and JavaScript we've been at like for multiple months trying to make it work well. And I think it just, people stick with their comfort zone. I think technology also changes and big companies rarely keep up.
so that's part of it, you know? Like a lot of these newer, sort of systems monitoring companies wouldn't exist. If, if these big companies were able to keep a product that worked really well. Right. and I think data's on a, really, a Datadog and a really good job of their core. But if you look at say Datadog APM, I'm like, it doesn't really do anything.
It's just like you slapped a PM on this thing that actually doesn't do a lot for a developer. And for me, that's really frustrating. Cause I got to deal with this idea of like, how is it different than Datadog? And I'm like, ah, it's another one. How's it different than logs, like back to square one. but yeah, so I think a lot of it's like technology changes, paradigms change a little bit, but not all that much.
but you know, I think it's mostly just like scale of data concerns. So. So I think we'll keep seeing that over, you know, probably the lifetime of, of software, but

**Beyang:** W would it be fair to say that, kind of the evolution of the production monitoring space of tools is kind of dictated by trying to solve the same essential problem, but for like each new computing platform or like paradigm that comes along, it just kinda, updating the model to fit to the, to that specific world.

**David:** I think some of it. So I'm going to give you an example of it's very much not that. So I'll get, I'll give you one, any, so let's take microservices. I still refuse to believe anybody truly operates with microservices because the complexity is just it's, it's ridiculous, like right. But service architecture has been around forever.
Right. And microservices, hypothetically, and like at a macro level are no different than service architectures, especially at like a Google scale. Right. And so that problem does not change anything fundamentally. Like the problem is the same problem. It's always been, you solve it in the same kind of way or kind of waste right on the counter side.
And this is a real issue. So we have an internal service that uses graph QL, which is Facebook's graph, query language that some JavaScript people love, which also introduces a ton of complexity. And one of the first things you see with complexity is all of a sudden, any version of tracing makes no sense because you have no aggregation points, because if you think about any kind of like performance overview, you need to be able to group things together, to be able to understand a meta, a higher level characteristic.
But the core idea of graph QL is you can just specify whatever you want in the query at any given point in time. So there is no aggregation point at all. And so then you end up with this question of like, does there have to be a specialized solution to that? Or do we need to modify what we're doing to just fit with a standard?
And I actually don't know the answers to those. Like there is actually like specialized solutions for graph QL performance monitoring, which is mind blowing. Like why should that have to exist? And. And now that's why I like like certain current generation of the world. There's like things like open telemetry if they truly remain open, which, you know, that's always a risky area, of course.
But like if they truly remain open and they get adoption, so they actually become a standard. Well maybe then we start adapting to standards instead of sort of forcing ourselves to recreate everything. Because like, obviously as engineers, we just like rebuilding things over and over. which sometimes is good, but often it's, it's two steps back and one step forward. you know, on, on open telemetry, I think one of the questions is the standards kind of evolve to fit the reality that has kind of emerged. And then when that reality changes. It's often like standards are kind of a lagging indicator, right? There's always, it it's, it's often like an individual company that identifies a need that's unmet by the existing standards and existing ecosystem.
That's tied to that standard and goes after that first. Do you think that open telemetry is general enough, kind of like future-proof or do you think that, you know, it's, it has evolved for the kind of the current trend in, you know, microservices or service oriented architectures and. after that wave crests, then it might become obsolete.

**David:** So I think for what it does. It's hard to predict obviously, but I think it does a good job for what it does. And I don't see it being replaced. Now, the problem is it doesn't do everything. So we wrote up a spec, which was very similar to open, not similar to open telemetry, that's giving our stuff too much credit, but it was basically a distributed tracing spec.
It was a distributed tracing spec based on our way of thinking, which is actually quite different than what open elementary achieves. And the way I would describe that is. Open telemetry is about small annotations, lots and lots and lots of small annotations. Like I read something the other day, it was on hacker news where, I think somebody on behalf of Twitter was suggesting that they had traces with a million plus spans and that's ludicrous to reason about like our stuff won't even support that right now.
And when I think about that, I'm like, okay, that probably makes it more useful. But the problem is when you think about spans, they're very, very useful because they suggest like function call at the end of the day. But if you try to use spans for actual profiling, like C profiling, like you're going to have hundreds of millions of these, and it won't work at all.
Like it's too fat of a data structure. And then on the counter side, if you need really rich information, which is what Sentry collects, it doesn't fit into that model because it's too big. Like if you had a million of these spans and all the spans are like 10 times the size, they are now no systems that are gonna be able to handle that.
And so I do think there's still gotta be middle grounds and. I think open telemetry, the core concepts will stick because the core concepts have been around forever and they make a lot of sense, right? At least the core concepts of distributed tracing and things like described in the dapper paper, open shell.
I'm sure it's evolved to have a bunch of other things. And I, I don't know if I have enough, in my opinion to say they're good or bad. But it does feel kind of like all specs where it just gets bloated over time and there's a bunch of stuff tacked on to please other people. So I don't know. We'll see.
I do think it's good either way. It's good to have better instrumentation built into libraries, but I worry that there's still an adoption curve. That's never going to get passed where yeah. We'll have this pretty good standard, which could solve a lot of problems, but it never will fully adopted.
Probably if nothing else, because to like implement the other side, the collector side, that's where a lot of opinions come into place and that can completely change how valuable the data is. So I dunno. And then I feel like there's not much else out there that's any kind of standard, right? Like even Sentry stuff, like at some point, a big company that I can't name suggested.
Oh, we should open source the error schema, and then they'll help us collaborate, blah, blah, blah. I'm like, why would we do that? Like, what is there for us to gain as a company? We're like the market leader open-sourcing it just helps our competitors. And I think on the counter side, I'm like, okay, this is a little bit of a segue, but one thing I always loved about Python was this concept of BDFL that Guido had.
and I love it because it said, I have an opinion. It doesn't matter if I'm right or wrong, but at least we'll keep going in the same direction. I guess Linux was a little bit of this way, too, right? And we basically said, that's what Sentry is like, it's open source, but it's not community built. It's very much like we decide what the direction is.
And I think that's truly, truly important. And I think this is often where things become crippled and they just stagnate is when there is not just like an overriding force of saying, no, we're doing this. Who cares? Like, just deal with it. If you don't like it, that's your problem. And so I would worry that about open telemetry.
but we'll 

**Beyang:** trying to please everyone. That's the, that's the fallacy you, you fall into.

**David:** And you could see like Kubernetes, I don't know, like there's Kubernetes is going to exist in five years. It's hard to say it's like super complex and there's a lot of stuff that keeps getting crammed into it. Like, 

**Beyang:** What's whatâ€™s your take on that prediction now will Kubernetes exist in five years? Go.

**David:** if it does, there's going to be another layer above it that anybody can understand. Cause like it's gotten so complex and so hard to reason about, and. And at this point, I'm like, okay, now we're, we're falling back and it's almost just a different version of Schaeffer or puppet or something else. It's just gone back into that bucket where it's just so complex and, and it's very case by case.
And I don't know. We'll see. But I, I feel like we create a lot of complexity in a lot of things we do as software engineers. And it's sort of, especially on the open source side. And we don't often do a lot to simplify that complexity. We just find ways to add more like NPM is a good example of this, but, yeah, I don't know.
As I, I remember talking to somebody, I was getting coached on doing a press interview one time and they're like, well, what do you care about? Like, what do you have an opinion on? And I'm like, honestly, the biggest opinion I have is that we've made it really hard to write software. Like when I started.
You were able to FTP a PHP script onto a server and it was live. You didn't have to do anything else. It was just, you can even edit the script or the file on the server. And it just updated in real time. Now I've got to like install a bundler. I've got to have multiple services running. I've got to figure out how to deploy this to AWS.
I'm like, I need all this other stuff, which, you know, for scale, a lot of that's good, but we certainly did create a massive barrier to entry for a lot of folks.

**Beyang:** W, why do you think that is? Do you think it's it's like necessary complexity just cause you know, modern applications had to be more robust. They have to reach more people and users. Or do you think it's, you know, there's some, there's something unnecessary about, all the, all the stuff that, you have to kind of set up on the deployment side these days.

**David:** I think it's both, some of it is certainly necessary. Like we've developed much better technology that like, we have really rich, fast acting user interfaces, for example. Right. And like that needs new technology and new hardware and all these other things. So I think some of it's needed and then do simplify some of it.
But then other side of things we're just stubborn and we like reinventing things. And, and you can see infinite versions of that. And so, I dunno, I think open source on one hand makes us better. Where if sort of predominantly there's a great open source solution to most core problems that are not your business logic.
You're probably gonna use that, frankly. Like why wouldn't you? And so I think that's valuable, but I, but the counter side of that is also like, Even like Sentry when we switched our license to BSL, they're like, Oh, I'll just fork Sentry. And I'm like, great. There'll be a bad version of Sentry in the world.
Won't be called Sentry, but it'll be a bad version of Sentry. And I'm like that, that will, that will be outcome. And all of a sudden, now we fractured again, we went from like solving the problem very well. And now we have two solutions that may or may not be solving it really well. And I think that's always what we break off.
And I think a lot of that. I don't, I don't know. So like, I'm not formally educated, like maybe part of this is education. It's like academics and like, you need to go through the, like, like more like computer history, but the problem is it changes so quickly. And the benefit of tech is you don't need that barrier.
Like you don't, you're not required to go through that. So I don't know. It's kind of one of those things that I, I don't know if there's a right answer.

**Beyang:** Yeah. Yeah. I also tend to think that like, You know, the history behind things. A lot of it ends up being narrative to kind of reinforce, like present objectives too. I think like there's always that kind of tendency bias, not necessarily conscious just to tell the story of the past and in a way that, favors what you want the present and future to look like.

**David:** that's definitely true.

**Beyang:**  tell me about, opensource. So you, you mentioned that. you know, if there's an open source, version of, of some thing that you wanted to play in a production you'll probably want to use that. And I, I definitely think that that's something that a lot of developers feel like I'd much prefer to use something that's open source, than proprietary and, you know, Sentry itself has open source. How did you kind of arrive at the decision to do that? And are there parts of, what you sell that are not open source and how do you kind of decide what the, the boundary line between those are.

**David:** so. So first Sentry was just started as open source, because I would just open source everything cause I, it was fine. I didn't care. Like, I never intended to build a business or anything like that. I, I liked the open source community. It was, it was really nice to be able to engage with people that were interested in your work.
Right. and so that's kind of how it all started and sort of, because of that and because we, it's self hosted, right? Like we actually just went down the path of like generally speaking, we can't use proprietary software. Because we're not going to be able to give that proprietary software to our customers.
And we want them to be able to use our product. Like we're optimizing around people using our product, like not profit or anything else at the end of the day. and I think over time, the open source ecosystem has shifted a lot in the sense of like when we raised money five years ago, everybody except, I actually think literally everybody except our seed investor, which was Dan Levine from itself.
and maybe even him frankly, are like, how are you going to make money on this? And we already had, we were profitable. We were making a healthy amount of money at that point. And they're still like, how are you going to make money on this? And I still truly believe it's my answer was it doesn't matter if we can't make money.
Nobody else is going to, like, that was very much our conviction. Right. And it was more like, just stop asking me this, we'll figure it out. Like you don't ask other people that question, like they don't make any money and you give him a lot of money, so it doesn't really matter. But so we started out as that.
It was like, no, we just like open source. Like we believe open source is a really good model and we don't see that, that there's a risk to it. And you know, over the years went by, changed a little bit. The next question was like, well, why won't AWS just run this. Like, if you build a big business, why won't they just do what they did do elastic.
Right. And we're like, doesn't matter, we'll solve that problem if it happens, like we'll just. Change the code base and say if AWS crash or something like that, right? Like it's just like, that was not what was important to us. It's like, we're just trying to build something that like all developers can use.
And that was the fundamental goal forever. And still it's, it's written into our values at this point. And we actually recently. I don't know, sometime last year change our license. It used to be VSD. and we changed it to BSL, which is just a proprietary license. It's proprietary, but it's somewhat known.
Right? And so if you call it open source, a bunch of people on the internet will yell at you. I frankly think there, they should stop giving people a hard time and they should value the fact that free software is still free, but, So that was our bridge and that bridge, like we created purely because, and I guess quick caveat DSL, you can do anything you want with Sentry, keep the license intact.
You can not sell a competing product to Sentry. And after I forget what our timeline is, two or three years, it becomes a patchy too. So it's kind of a, like a, in my opinion, that's a good license. And everybody that is doing open core something similar should maybe consider BSL. Or if they're thinking about a new license,

**Beyang:** If I want to deploy like Sentry within my organization, I can spin it up for free and not have to worry about being bound by any proprietary license, as long as they don't launch a competing product.

**David:** Exactly. And that's important to understand why or why that is important is because we don't actually have any proprietary features or code as part of the core of Sentry. We have, we do have proprietary code, but it's our infrastructure and things like that. Like what you see on get hub is literally what we shipped to production multiple times a day.
Right. We shipped some other stuff like billing code and stuff next to it, but that's why we wanted this because what we can still give it away for free, which was our goal. It was accessibility. It wasn't. Oh, yeah, you should fork and use our code. And like steel is legally the wrong word, but like, you didn't build it.
Why should you have all these rights to do whatever the hell you want with it? You shouldn't it's entitlement. Right. And so that's, we just took a moral stance where like, this is what we believe is right. And Justin will do it. And so we made that change. but frankly we mostly made it because, I won't name names, but like startups randomly taking our code and not crediting us.
And I was just like, I'm tired of this. I don't have the mental energy to deal with these annoying companies. it wasn't because we were afraid of AWS or anything like that. I think they'd rather partner than try to run it, so it's not a big deal. but yeah, it's, it's just, we've always had that conviction.
And so like by default, basically everything at Sentry has been open source and every company I've worked at has strongly encouraged or given freedom for open source, both, you know, Dropbox and discuss we're really, really big on that. which I valued a lot and I think often goes unappreciated. but it wouldn't be cool to see more companies.
and I, and everybody hates on Facebook these days, but like, I'd like to see more companies contribute in ways like Facebook has like, react is phenomenal for the industry. Right. And they've done so much for that space. And so, so hopefully we get to see more and more of that because like, once you've got corporate sponsorship from that kind of way, right.
It's not necessarily a community building react. It's Facebook. Like you're actually able to build a really great product. So, yeah. But I dunno, I think it's a, it's a great industry. It's just open sources, generally hard to monetize. So I think. That's the challenge for folks.

**Beyang:** think there's, there's a lot of especially developer tool creators, who want to kind of. make the right trade off there. You know, like developers love open source for good reason. You know, there's nothing worse than, having a tool that breaks in some way where you can't dive into the source code and understand what's going on. But at the same time, you know, got to pay the bills, got to, you know, build an engine that actually sustains a business. So you can continue to invest in improve the tool. And that's, that's kind of an ongoing challenge. kind of going back in time to the origin stories of Sentry. 
So you mentioned that you, you started it while you were at discus.
Can you talk through, you know, what motivated you to create it? And, you know, what, what the project was like in those early days?

**David:** So Sentry going back to even MIRC guys. Cause this is how old that is. I was in a Django, the web framework. I was in a Django users channel. So someone of does the mailing list would be, and somebody asks. Very simple. I would just help users and somebody asked how to log heirs to a database so they can put them on a dashboard.
I'm like, Hmm, why would you do that? And I'm like, this is how I would do it. And it was like 70 lines of code. And I published that. I called it Django, DB log, very, very clever name. And, and that was that. And then I just like hacking on things. So over the years I added a few features cause I'm like, Oh, this is kind of cool, I guess.
And it, it was also during the time when Django was booming and I became somewhat prolific in those days in Django, in the sense of, I built a lot of fans that Jenga folks used, and this was one of them. And when I joined discus, they were using this. And so I'm like, Ooh. And actually the first month it might've been the first week I actually took the discus service down.
and it got even worse because of Django DD log because of the original Sentry. it just, it couldn't scale and in scenarios where you had catastrophic failures. And so it just took us longer to recover, right? It's like, okay, let's fix this. Like let's actually make this work at the scale that discus was cause they were pretty significant in request volume at the time.
And so that's when Sentry was born, I still had a different name. It was Django Sentry, but we'll ignore that detail. and then I was at discus for about three years. A company always was pretty small when I was there. I think maybe when I left, it was 60 folks. so, you know, you can think of small as like we had a lot of, sort of autonomy and freedom.
Right. And, I would just generally build a lot of open source stuff and I would try to improve our tools and things like that. It's sort of my side projects and Sentry I just kept hacking on. And the thing that I think. And people don't give up source enough credit. They often complain, like, why should I, I contribute or something like that.
And then you talk about resumes and, and for me it was like, well, I'm contributing. Cause like there's a bunch of companies that think what I'm doing is super cool. And I value that, that like makes me happier. In this case, it was companies like event Brite and Mozilla and Instagram and, and all of us were like up and comers to some degree, at the time and all on Django.
And so that was just exciting to me. So I got to network with a lot of peers that were really smart. And then over the course of that three years, I, asked my, now co-founder to help start like Sentry the business per se. and so we did, I spun it up right before leaving discus. and then, you know, ran that, I think for, I don't know, between two and a half, three years, something like that.
during my transition from discuss through Dropbox and 

**Beyang:** You're running the business on the side, as you were a full time engineer at Dropbox.

**David:** Yeah. and at first it was great. It was not a ton of work. you know, as you get bigger, the success per se comes to you. It gets much trickier, especially with an infrastructure monitoring tool. Like you're collecting a lot of data. There's a lot of services that are running. So, and especially when you're bootstrapping it, like, I'm actually very proud to say, asterix of whatever the corporate filings say, like, I put no money into the company.
And nor did my cofounder, nor did anybody else. It was bootstrapped from $0 million. we didn't have to pay our own salaries, which was very fortunate, but it was effectively profitable from day one, day one until, you know, sometime in VC land. and then, so we ran that for a few years, right. And I think, you know, when I was looking at Dropbox size, they're a little less than two years, Dropbox had grown really fast at that time.
It'd become like, to me, what was a big company? It was over a thousand employees when I left and it was like 250 ish when I joined. And at that stage of company for me at my, we'll call it my maturity level at the time or my professional approach at the time. Like, I didn't like that kind of company, but it wasn't empowering for me.
I didn't feel like I could get anything done. I had to deal with a lot of politics. I'm just like, you know, this is not for me. I have this other thing. It's become an intense second full time job. I can match my salary now, so I don't even care. and so we just like myself and my cofounder, who's a get hub at the time we just quit our jobs.
We're like, cool. We can do this full time. And then like, Ultimately, as soon as you do that, you take it much more seriously. And we looked around and we saw all the competitors that had sprung up and I'm a very competitive person. And the first thing I thought is I'm like, we are certainly not going to let them take over, like, take what we built kind of thing.
Right. none of them were open source or anything. And so we were like, we have this moral high ground and we've been doing this for so long. It's sort of like, we've earned this opportunity. Right. And so then we went out and we raised the money. And when we did that, that was the turning point. That's when we said we're not raising money, just like, so we can hire some people right now we're raising money to build this into the biggest thing that can possibly become.
Like, it was very much like we never talked about what an end was. We just said we build a bigger and that's it. And so that's kind of what we've been doing ever since. And that's been five years now since we raised that seed round.

**Beyang:** Yeah, that's awesome. Can, can you talk about, so, you know, you, you mentioned that, Sentry kind of grew out of, Django roots, and that was kind of a, an era of web development. That was, you know, it was like the, the age of the monolith, so to speak. And the landscape of course has evolved over the years, both in the form of, you know, like web development. Now there's more multi-service. applications, server lists is a thing. And also, you know, additional computing platforms like mobile has grown, there's things like, you know, IOT now, edge computing. If you consider that a thing that didn't exist a couple of years ago, how has a Sentry evolved and adapted with the times?

**David:** So we've always iterated on what we do from a think about it from a data collection or instrumentation standpoint, we've always tried to adapt to frameworks and stuff. But what I actually think is super interesting is our core design is still honestly, it's what you need still today in all paradigms.
And I think that works really well for errors. It kind of makes sense. Like all errors are kind of shaped the same. we did have to make some changes along the way. Like a tangible example is, When you are running iOS code, there's a lot of threads running and it may not be the main thread that's crashing or something.
So we had to adapt the system to handle those kinds of cases or JavaScript all the, all the code is compiled and minified in a fuss gated. Right. And how it's transpired from two different languages into like the like coder actually running. So we had to adapt the system to transform everything right.
And that's basically the model we still run today. It's like, we just have transformers. It brings it back to the core and it works for every application in the world. And I actually say that like, literally, like we have so many different kinds of applications to me that's like really excited. And I like, console apps, browser, desktop IOT, like firmware EHRs are coming up to us every, like nearly every web app in the world.
Like it's, it's just really cool that that core works so well. And you know, we're a monolith ish ourselves. And we actually even make sure Sentry supports monolith in a really good way, just as we try to make sure it supports service oriented in a really good way. And some of that was just because, you know, we decided to go down this route, so we had to solve our own problem first.
Right. and so I think that's been, that's been really good for us. I think some of the challenges have come down to it. Like I mentioned, the graph QL thing, which is tricky, When you get into performance, it's much, much harder. Like a crash is kind of a crash, no matter how you look at it with the caveat of like, what's a crash in the browser, right.
That's a little fuzzy, but you know, you can reason about it, but what is a, so we call our performance stuff transactions. So a request response, right? That's a transaction. What's a transaction in a mobile app. I don't know. It's kind of whatever you think it should be, frankly. maybe it's a view, you know, maybe it's some other action that you take or something.
And so we just, like, we spent a lot of time trying to reason about how can we create a model, just like our air model is that works for all of these paradigms. And that's why I went back and I was saying like, you know, everybody solves for the easy problems. First they solve for infrastructure. It's a very simple known quantity, JavaScript, desktop, and mobile IOT is even worse, but like, Those are really complicated things like scenarios to solve for, especially if you want a truly universal solution and, and you might argue universal doesn't matter, but it does matter because applications are so complex these days and the same argument for tracing.
It's true here. Like your mobile app is communicating with your API. I don't need to understand the API as a mobile developer, but I do need to know that it's the API fault and I need to know it. And the only way I can truly know it as the API is fault. Has because the API changed and the root cause can be, can be diagnosed in the API itself.
And so because of that unique connectivity, which is why you actually need that universal platform. And so that's what a lot of our challenges, but I think the core and going back to, like, I think we're just recreating new solutions to the same old problems. And I truly believe in that because centuries, like, I don't know if it's 11 or 12 years old, but it's still the same as it was, you know, that long ago fundamentally at its core.
So.

**Beyang:** Do you, do you view performance monitoring as a different problem from, error monitoring or are they one in the same? And if they are one in the same, you know, how, how do you decide what actually is an error versus just, you know, tolerable slowness in, in an application.

**David:** so I would say they're different, but I would reason about, so. to give you insight, like we said, Sentry's goal. If what Sentry does is it says, Hey, here's an error I'm telling you about it because you caused it. Here's the commit that caused it. Like, if that's fundamentally what we're trying to do today, what we're shifting towards is, Hey, you made a change to your code.
Here's all of the things that went wrong. Like, if you can imagine anything that can go wrong from that, we want to be able to identify any of those problems. I want to call them all errors though. At the end of the day, they might be defects or problems or something like that. or in Sentry terms issues. but they all exhibit very different characteristics. And I think some of it's frankly, up to the business's side, what it means, right? Like, my analogy is always like, if you were at crashes, obviously we know that's bad. There's no questioning that. But if the Uber app sits at a loading indicator for 30 seconds, is that bad?
That's probably the same as a crash for all we know it's going to sit at that loading indicator forever, and it's never going to change, right. That might not even be slow behavior though. At that point, that's just, something's not working and isn't causing an error and isn't slow. And so that's actually another thing we think a lot about like, if signups go to zero and you can correlate it with a release that is a software monitoring concern.
And that's something that most people don't try to address with their monitoring tools, but it's such a fundamental, like, not only is it super critical, but it's such a fundamentally easy thing to do too. It's just like, okay. Requests and assign a pinpoint flatlined or successful requests at the very least we made a change related must be, you know, there's a high correlation, right?
Like, so that's fundamentally how we thought about it. So I think if you live in APM land, you say it's all the same thing. Cause it's performance, but in an abstract way, If you're a developer performance generally means latency. It doesn't mean errors. So.

**Beyang:** And so like when, when you're defining, you know, what constitutes an issue or not, is that something that you define in kind of the, application code? Like, Hey, if this condition happens, send a, like a, a thing to the Sentry API, or is it something that is more defined, like after the fact, like you're collecting all this data, you know, you're collecting things like request response times and you notice a spike in one particular metric.

**David:** Yeah. So for errors, it's very straight forward. It's like, it's like a try catch statement effectively. So like everybody kind of gets that for performance. We basically collected all, we're going to have some sampling algorithms, down the road, but right now it's just collected all you can client-side sample if you want.
and then you can ask questions. So going back to this observability idea, like we have the data so we can, we can monitor well, We might find, we don't need to store the data, but there's a lot of value in having access to that data. And ideally it's cheap enough to store. So our solution is just like errors are in their transactions are in there.
we collect some other kinds of data, like, some security reports and things like that. We just call them events internally. So just, we collect a lot of events and the advantage that we have with events and doing the way we do it is it's all structured. There's, there's meaning to everything. And that's such a powerful idea.
Like. Never build a platform, just build structured data, like build schema. Schema is, are so helpful in everything in life. Like, like abstractions are, are valuable, but like, you know, you can't have everything be an abstract.

**Beyang:** Yeah,

**David:** AI doesn't truly exist these days.

**Beyang:** it's just pattern matching. Yeah. Can I get your like opinionated take on best practices and anti-patterns in. production monitoring. Like if I'm, you know, leading a small team inside a large organization, or if I'm developing a new application myself, what are the common pitfalls I'm going to fall into and what should be kind of the framework that I tried to, use when I think about like what tools I should use and how I go about having my team debug production issues.

**David:** Yeah, I don't know. I think. There's this concept test in production. I hate that. Like one time I had, somebody we'd hired and they're like, Hey.

**Beyang:** that concept first?

**David:** Okay, so test and production. I'm just going to take it in the literal sense. Like, we didn't really test this code while we shipped it to production in a broken that's.
Okay. That's not okay. That's never, okay. I do an explain to an employee one time that that's never okay. It doesn't matter what our software is for. Like our software's for detecting those bugs and making it so you can quickly remediate them. Right. But to quickly remediate you stuff, to do a deploy, you have to deal with customer fallout.
So it's never okay. And that's why I don't like this idea of test and production. Like it's a really cheeky way to say. That you should be willing to accept risk, right? it's, it's move fast, but don't break anything like that's, everybody's objective and I don't know, that's such an important concept to me.
So, and what I'm alluding to with that is just like CIA and CD is super important, like with, with any new software or any new team. The first thing I would do is focus on a fast release life cycle. And the unfortunate truth is that's really hard to maintain. Like as applications get bigger and more complex, as infrastructure gets bigger and more complex, it's really hard to do accurate testing or fast testing or both.
but I think that's the most important thing you can do from a sort of just prevent the, the need for production monitoring. But then I would say you adopt first application monitoring before any kind of systems monitoring like yeah, you might need systems monitoring, you might need metrics and stuff, but you can get away a really long time without any of that.
Like, I truly believe if you throw a Sentry in your application, you might not need anything more until you're like a pretty significant size organization, because errors are going to be your number one enemy at that point. Like you're going to catch a lot of things in development, but you're not going to catch it, capture everything.
And so I think it's important to do something there. I don't know though. I. I frankly, don't spend a lot of time. Like I set up Sentry on new projects now and I'm like, Oh, it kind of works. I usually have to tweak a few things and make it fit my need a little bit more, but cause everything else it's like the barriers are so high.
Like, we have this, CEI service that we run it's public, but I'm pretty sure we're the only consumers of it. And it runs all these different services. It runs a queue and it runs like a database and they're all offloaded to somebody and there's no ops people. It's literally, I just do it in my free time.
And it's always breaking and it's never breaking because of code anymore. It's breaking because like really cryptic stuff is going wrong and I'm like, it is so hard to get the right instrumentation in there. And so, I don't know. And that's why I'm like, that can't be the solution to the problem. They have to be better ways to solve it.

**Beyang:** Makes sense. what are your thoughts on deploying on Fridays and kind of the risk that incurs.

**David:** I'm of the mindset that avoid incidents, but don't avoid them, but it's like security by obscurity, right? It's the same thing don't deploy on Friday because it might break everything. Don't break everything. Like that's a better solution than don't deploy on Friday. Like. I don't know, cause we actually had this problem a lot as a young company because we actually have three offices, one in San Francisco, one in Vienna, which is plus nine, I think.
and then one in Toronto, which is plus three for us or minus I guess actually. And so they will deploy in the middle of the night and still today at 120 plus people in the company, they will sometimes take down everything for the most part. They they're fully staffed and they can handle it. But. Those less, those situations suck for both the customers and the company, but you have to accept them and you accept them because then you say, how do we let this never happen again?
And that's super important. That's like a super critical part of incident management. Right. And I think that's, that's what you do. You say, it's fine to deploy on Fridays. Don't deploy after 5:00 PM because nobody should have to like, you know, get up just because there's something I think those rules are kind of okay.
But I also think it's fair to empower people. And I don't know, I'm a believer in, you know, hopefully we're all adults, you know, clearly with current events in the world, that's not true, but I would like to believe that that ideal is fine, to the sense where like anybody at Sentry. Can literally anybody with a corporate email address in Sentry, unless we've changed, it can deploy Sentry.
And actually, I think they can deploy any application in production. Now they can't necessarily change the application, but they can initiate the deployment life lifecycle. And we say, that's okay, because CIA is responsible for saying this is safe to deploy. If it goes into master, it better be safe. And so I think that's really what you got to aim for.
And monitoring is your safety net, to the point where. We sort of said our 10 year vision is like, we'd love to get monitoring to be part of testing. Like if you could Canary every change and actively use monitoring. So you still write tests obviously, but if you could just use real monitoring, real production monitoring, where you could diagnose those things that aren't tested, but you could do it before it ever happened.
Your customers that's the ultimate solution to the problem, right?

**Beyang:** Interesting. So would that, like in your CIP plan, you kind of stand up, like an instance of your application with all the monitoring stuff, you'd hit it with kind of a test workload, and then you'd observe the metrics. Is that kind of the

**David:** Yeah. That's like a, a practical way. You could do it right now today, right? Like, like. We built this thing during a hack week, where all it did was it was basically a web scraper. It just tried to, I forget what I called it inhuman. I think it just tried to simulate some really poor user behavior, like really dumb AI.
Right. And we actually ran it. And so it would inject sensory onto websites and it's like, man, in the middle of the websites and inject Sentry, and then it would just click around and fill out forms and stuff. Right. And the demo for hack week was kind of interesting because like some sites, it was really hard to pull off.
Like, I don't know what airlines are doing, but. But for example, there's this pizza company in Canada called pizza pizza. And if you loaded this up on their website, it found all the bugs. Now, as a user, you load up the website and you instantly find all the bugs. It it's just broken all the time, but like, I'm like, that's a, that's a visible version of what the future can be.
And so I think what you're talking about is, is applicable today, but I think there's a real future with technology. If we can figure out state management and databases where we can actually fully Canary production applications where, you know, it's like blue, green and stuff today. Right. But if, if instead it's blue, green, it's literally like blue, blue, and all your customers are over here.
And they're also replicated over here, but that's a different version of your application, but they're not actually experiencing the results. Like that's the ideal world, but that technologically wa or like from a technology standpoint, that's obviously like very, very hard to achieve. and it wouldn't be just us responsible for that at the end of the day.
But, you know, it might be possible in our lifetime to, to see something like that happen.

**Beyang:** Yeah, it makes sense. You mentioned your kind of tenure, vision. And I wanted to kind of ask you about how you arrived at that. Cause you know, In our conversations, both, you know, this one in an earlier I've picked up a strong ethos from you of being like super down to earth, being driven, kind of by like the immediate pains that you understand.
how does, how do you derive kind of a tenure vision out of that? Doesn't that require you to be a little bit more like head in the clouds highfalutin a bit. so, so how did you arrive at what, what your vision is.

**David:** Yeah. So, you know, an exercise you get, whenever you pitch VCs is like, what's your mission statement or whatever that, that garbage is. which frankly I think is a waste of time. mostly because it changes every pitch deck, so it doesn't matter. but. I don't know, at some point, one of my friends told me to read this book, which I did not.
but it's about root cause analysis and it's something like the five whys it's it's by some manager. And it's like, you ask yourself why like five times to get to the root cause that's the idea. And I never do it five times, but I'm always like, okay, why, why is this, this, why is this, this? And I use that to work backwards.
And so we basically use that to like root cause with our mission statement. And we very simply said, okay, What is Sentry what's monitoring. Okay. Monitoring as part of the application life cycle, the development life cycle. Okay. Development is like an efficiency thing. And then we're like, actually like what's software for, well, this is the simplest way to reason out software only exists for productivity.
There's nothing else about it. And so we started there. And then we said, okay, if that's true, which we just have to agree, it's true because it's hard to argue against that, but monitoring must now only exists for productivity because it's only in there to enable software development at the end of the day.
And so we're like, well, how would we get monitoring to make us more productive? Well, the tactical version is you ship books to production and you can never stop that. And so we make it faster to remediate those bugs and then the better version would be well, what if we could prevent those bugs from happening?
Because that's a much better outcome in life. And so that's really where he ended up at like, is there a real way we could get there that somebody that's technical and well-educated well-informed could believe in. And I truly believe that we can get there via what I'm saying, and it's not that much of a reach.
Impossibly hard these days. but I'm very confident that there's at least a few companies in the world that could do what I'm talking about right now today. And that's super exciting. So, yeah, so we just kind of worked there and I actually think that was important because it, it helped guide us because if you think about your goal is that, well, I want to be able to put monitoring into CGI and then identify the bugs that the tests are not catching well, you first need to be able to identify all the problems and that's fundamental to monitoring, right?
And so you can sort of do those goals in parallel. You can do one before the other kind of thing. but that's how we reason about it. So it was just like this forced mental exercise, which was frankly really, really good, but it's also a little bit abstract in that. It's not like we're actually working towards that right now, even though we can say we sort of are right.

**Beyang:** Yeah, that was my next question was going to be practically speaking. You know, how do you use that vision and for like planning purposes, it, does it just serve as kind of a backdrop? Or do you actually find yourself saying like, well, you know, we should prioritize this over the other thing this quarter, because that brings us a step closer to our vision.

**David:** I only use it from the point of view to help people understand what we could achieve. Like what is a big picture item? Right. When we think about planning, we have much more core tenants that we follow. So for example, when it's front end first, like we're very hyperfocused on, like we must solve for the front end customers first.
you know, market share is one of our core tenants. we call it every developer as part of our values. we actually have a bunch of values that are not specifically about people. We have one that's about people and then everything else is just about how we operate. so one is that Sentry is for every developer, we're here to enable every developer and that can mean many things, but the easiest way to reason about it is like, we want to solve the problem for every kind of developer in the world.
And so that dictates a lot of like, is this guiding that, And, and that's kind of how we reason about it, but it's very easy to say, well, like we need to be able to monitor for more problems because we can't monitor for the problems. We can't bring monitoring earlier into the life cycle. It's just useless at that point.
Right. But we never actually talk about the big grand vision other than like, Hey, you're the new hire. Here's a crazy idea kind of thing.

**Beyang:** Yeah. You mentioned that Sentry is, is for every developer. you know, I talked to a lot of developer tool, creators, and one recurring problem I hear about is, you know, let's say you sell into an organization and the people who bring you in are, you know, super gung ho about your product. but then there's kind of like the remaining, developers at the company who may have never heard of you or, you know, don't know what you're all about.
is that a challenge for Sentry just like spreading awareness inside your customers? and if so, how do you, spread the word.

**David:** It definitely is a challenge. this is something we're iterating on. So Sentry has always been product led and that's frankly, because I didn't know how to do anything else. And so we're starting to be a little bit more on the sales and marketing efforts. And I say that because our version of that story that's successful is like some of it's going to be organic.
It's going to be product led. A lot of it is like bigger companies and those bigger companies value different things. And so for example, we've started trying to like offer our customers sort of more hands on learning, which is like, Hey, we'll have like, I mean, I guess not in person anymore, but it's like, we'll come in.
We're happy to sit down. We can talk a little bit about roadmap. We can show you a little bit more how Sentry can work in these different scenarios. train some folks on it. I think that's been a really good way. you know, that's a very, I don't wanna say enterprising, but it's more of a. A high touch solution to the problem, which is often expensive on the other side, I don't know, like it's tricky.
And I think it's especially tricky with developers because we're all somewhat empowered to choose our own technology these days, especially because we make a lot of it affordable. and people can just swipe the card, which is great, but we're also all empowered to build their own stuff at the time, which also creates some, some dilemmas.
And so I think there's still a lot of fragmentation, right. We're definitely the market leader in our space by any number you would look at and it's by a large margin. But what you'll find is even in some of our accounts, some of our competitors are in there and like small little silos. And I'm just like, but why, like, why would this be possible?
And you know, sometimes our competitors do a good job, but there's other competitors that are just like, like below the bar in every way you would measure them from like a product usability from a price point, all this stuff. And I'm like, why wouldn't you just consolidate? Like, why would you not just put it all on ours?
And so to some degree, I think building a developer, a business, you just sort of have to accept that it's probably a war of attrition. Like you just have to accept that over time. You're going to win developers and lose developers. And there's no real change in that because people always want to explore new tools and we let them, and there's always going to be changes and developers are also like always interested in new technology.
So, so I don't know, it's a tricky problem. I'll let you know once we've solved it, but I think it's just.

**Beyang:** And I think there's also like a strong culture among developers of kind of preserving that freedom of choice. Right? Like any tool that tries to lock you in, if people perceive you doing that, that's, that's a huge, negative, I think.

**David:** Yeah, no, I, I, I fully agree. And, and even the people like, frankly, most people should not care. That Sentry is open source ish. Like, it doesn't really matter to them. They're never going to run it themselves, but we hear like many times it's like, well, we picked Sentry because it's open source. I'm like, Yeah, you're using our assessors.
Why do you care? And it's like, well, like maybe one day, if like your company shut down, we can then run center yourself ourselves. I'm like, what's never going to happen. So why do you care? Like, like it's, it's almost unreasonable that why they make the choice, but at the same time, it is like, it's an important part of it.

**Beyang:** Yeah. So yeah, most great tools that I'm aware of, especially developer tools, are ones that you kind of build for yourself. you solve your own use case, scratch your own itch. First as Sentry has grown as a business. do you find yourself having to balance building for yourself with also listening to feedback from users who might not have the same opinions or view of things, as you, and, you know, if so, how do you do that?

**David:** I would say yes and no in the sense that I will outright tell you that we're not going to do something because I'll probably be nice about it. But generally speaking, it's a bad idea. I will still do that today. Like if you asked me if we're going to build something, I'll say no.

**Beyang:** What are, can you name some, are there any examples that come to mind of things that you said no to that people have asked for?

**David:** I'm trying to think of something in recent history. I mean, I did just tell everybody we're not building anything to solve China. that's a little bit different of a problem, 

**Beyang:** Oh, like, the Chinese market. 

**David:** Yeah. I'm like, I don't care if there's a bunch of customers asking for us to support China, it's not happening kind of thing.
It doesn't matter if the customer is like, sort of requesting or demanding that feature. That's not where our focus is right now. And we are big believers in that idea of focus. Right. I would say we bend a little bit. So we have a team that we have a collective of teams, but one is enterprise and they're just there to solve these sort of edge cases for our largest customers.
And that is very much traditional product. But most of Sentry's investment is R and D, which I am hyper opinionated that R and D has to be opinionated. It can not be like a traditional product management scheme where you're like, customer, tell me what you want. Okay. I'm going to sort of build that for you.
It's gotta be like, I have an opinion on what the right thing to do is, and we're going to build that and we're going to prove that worst. So we're going to prove that does it. And that's a V that's a very particular way of doing things, but it's a way I believe in when you're, If you're ever going to do something serious and actually innovate.
Right. so, so I'd say we have a mix of both, but, but yeah, generally speaking, we're fairly open with our community. Like one thing I really valued early on a Sentry is we used to get hub for all of this kind of stuff. And unfortunately we moved away from that, but where like people could ask about stuff, we'd publish it on there.
We we'd respond to folks' questions on there. Like it was kind of like all out in the open, our roadmap and development. And I know get lab does this, but. When it was on a single repo, it just seemed, it was very tangible and easy to reason about to the point where like, if a customer opened a feature request ticket through Zendesk or a bug report, we would just open a ticket on GitHub for them and link them that ticket.
Or we'd open even better. We'd open the pull request and we'd link them the pull request that fixed it. And that was such a great solution, but it was almost always, I mean, it's, it's almost always just been like, no, we're not doing that. Actually. I can remember a bunch of times now, like, There was a big company that asked us to implement some weird analytics in the UI.
And I'm like, no, like why would we do that? And they probably would have paid a lot of money, but it was okay.

**Beyang:** Yeah, it makes sense. So you got to like factor other feed feedback into account, but at the end of the day, you gotta, you gotta be, be opinionated. Cause that, that kind of, it's hard to be focused without being opinionated, I guess. Cool. are there any other tools or technologies that you're excited about on the horizon?

**David:** What am I excited about? I don't even know. I have a hard time keeping up these days. I've really enjoyed, modern iterations of JavaScript, barring the complexity and stuff. Like I hack on a bunch of things in my spare time. I just recently picked up TypeScript, which I had mixed feelings about, but, I haven't really used many tools in recent history.
I love GitHub actions. I also love that get hub does not charge us when they probably should. so hopefully they don't fix that. Yeah. But, that's probably the only product I've used in recent history that I'm like, Oh, I, it's not perfect by any means yet, but, but it's also a soft spot for me, like CIA and CD.
yeah. I don't know, like honestly, most of my days are spent like, Around my calendar now and, and, and sort of planning and communications and stuff, unfortunately. but yeah, I don't know. A lot of my personal time has been like messing around with like smart home type stuff and, just toying with technology again.
So

**Beyang:** Awesome. So for those listening, who, you know, they're, they're interested and they want to try out Sentry, how would you recommend people get started with it?

**David:** go to the website, click sign up and do what it tells me. Hopefully, as long as you can deploy quickly, you'll be up in a few minutes.

**Beyang:** My guest today has been David Cramer. David, thanks for being on the podcast.

**David:** Thanks again for having me.
<!-- END TRANSCRIPT -->
