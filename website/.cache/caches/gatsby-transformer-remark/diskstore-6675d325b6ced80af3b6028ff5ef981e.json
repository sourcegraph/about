{"expireTime":9007200905229171000,"key":"transformer-remark-markdown-html-c27a7dcc0602832dfb5afc9a6cb97649-gatsby-remark-autolink-headersgatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-unwrap-imagesgatsby-remark-imagesgatsby-remark-smartypants-","val":"<img src=\"/blog/blog_Reduce_RAM-01.jpg\" alt=\"Zoekt memory optimizations graphic\">\n<p><em>Sourcegraph universal code search enables you to explore, navigate, and better understand all your code, faster.</em></p>\n<p>Recently, we’ve been working to scale Sourcegraph cloud’s index to <a href=\"https://about.sourcegraph.com/blog/why-index-the-oss-universe/\">1 million open source repositories and beyond</a>. Part of that effort has been reducing the RAM usage for the <a href=\"https://github.com/google/zoekt\">Zoekt</a> (pronounced “zooked”) servers responsible for handling most of our code searches.</p>\n<p>Zoekt is a Go program created by Han-Wen Nienhuys that performs <a href=\"https://swtch.com/~rsc/regexp/regexp4.html\">trigram-based regex search</a>, which means that it builds an inverted index mapping every three-letter sequence of characters, or trigram, to where it appears in a repository. Each entry in the list is called a posting, and the list itself is called a postings list. When searching for a string like <code class=\"language-text\">Errorf</code>, Zoekt will iterate through the postings lists for <code class=\"language-text\">Err</code> and <code class=\"language-text\">orf</code> to find offsets where an <code class=\"language-text\">Err</code> trigram is found three characters before an <code class=\"language-text\">orf</code> trigram. The locations and lengths of these postings lists on disk are kept in RAM, along with various other metadata, to make searches go faster. Determining that a repo has <em>no</em> instances of a trigram that is required by the input lets the entire repository be skipped.</p>\n<p>In the below image, the large purple area on the left is the RAM used by the 20 Zoekt replicas alone, and the tiny lines under it are all the other jobs. The drops represent deploying the changes described in this post.</p>\n<img src=\"/blog/ram-usage.png\" width=1200 alt=\"RAM used by the 20 Zoekt replicas\"/>\n<p>Here’s how we achieved a 5x reduction in memory usage with no measurable latency changes.</p>\n<h2 id=\"Step-1-Measure-how-a-servers-RAM-is-being-used\" style=\"position:relative;\"><a href=\"#Step-1-Measure-how-a-servers-RAM-is-being-used\" aria-label=\"Step 1 Measure how a servers RAM is being used permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 18 95 120\" height=\"18\" width=\"18\"><path d=\"M53.69,78.7H37.94l-5.85,25H21.74l5.85-25H15.89L18,69.1H29.84l4.65-19.65H23.39l2.1-9.6H36.74l5.7-23.7H52.79l-5.7,23.7H62.84l5.7-23.7H78.89l-5.7,23.7H84.74l-2.4,9.6H70.94L66.29,69.1H77.24l-2.4,9.6H64l-5.85,25H47.84Zm-13.5-9.6H55.94l4.65-19.65H44.84Z\"/></svg></a>Step 1: Measure how a server’s RAM is being used</h2>\n<p>As a first optimization step, a test corpus was created from one of the Zoekt backend servers, and a memory profile was collected to measure precisely how a server’s RAM was being consumed. The corpus has 19,000 different repos, 2.6 billion lines of code, and takes 166GB on disk. Go has <a href=\"https://golang.org/doc/diagnostics#profiling\">built-in profiling tools</a> with deep runtime integrations that make it easy to collect this information. The memory profile below shows 22GB of live objects on one server. The actual RAM usage of a Go program depends on how aggressive the garbage collector is. By default, it can use roughly twice as much memory as the size of the live objects, but you can set the <code class=\"language-text\">GOGC</code> environment variable to more aggressively reduce the maximum overhead. We run Zoekt with <code class=\"language-text\">GOGC=50</code> to reduce the likelihood that it will exceed its available memory.</p>\n<figure>\n  <img src=\"/blog/22GB of live objects on one server.png\" alt=\"22GB of live objects on one server\" class=\"no-shadow\">\n  <figcaption>22GB of live objects on one server.</figcaption>\n</figure>\n<p>The memory profile shows which functions are responsible for allocating RAM, and it’s immediately apparent that readNgrams is responsible for 67% of the memory usage. Digging into <a href=\"https://github.com/google/zoekt/blob/d5ee8b074530f291e1173f8e79f7fcdb4d972cc5/read.go#L256\">the code</a>, this turned out to be a function that builds a map from trigrams to the location of a posting list on disk. It’s building a big mapping from 64-bit trigrams (three 21-bit Unicode characters) to 32-bit offsets and lengths.</p>\n<div class=\"gatsby-highlight\" data-language=\"go\"><pre class=\"language-go\"><code class=\"language-go\"><span class=\"token keyword\">type</span> ngram <span class=\"token builtin\">uint64</span>\n<span class=\"token keyword\">type</span> simpleSection <span class=\"token keyword\">struct</span> <span class=\"token punctuation\">{</span>\n\toff <span class=\"token builtin\">uint32</span>\n\tsz  <span class=\"token builtin\">uint32</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">const</span> ngramEncoding <span class=\"token operator\">=</span> <span class=\"token number\">8</span>\n\n<span class=\"token keyword\">func</span> <span class=\"token punctuation\">(</span>d <span class=\"token operator\">*</span>indexData<span class=\"token punctuation\">)</span> <span class=\"token function\">readNgrams</span><span class=\"token punctuation\">(</span>toc <span class=\"token operator\">*</span>indexTOC<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">map</span><span class=\"token punctuation\">[</span>ngram<span class=\"token punctuation\">]</span>simpleSection<span class=\"token punctuation\">,</span> <span class=\"token builtin\">error</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n\ttextContent<span class=\"token punctuation\">,</span> err <span class=\"token operator\">:=</span> d<span class=\"token punctuation\">.</span><span class=\"token function\">readSectionBlob</span><span class=\"token punctuation\">(</span>toc<span class=\"token punctuation\">.</span>ngramText<span class=\"token punctuation\">)</span>\n\t<span class=\"token keyword\">if</span> err <span class=\"token operator\">!=</span> <span class=\"token boolean\">nil</span> <span class=\"token punctuation\">{</span>\n\t\t<span class=\"token keyword\">return</span> <span class=\"token boolean\">nil</span><span class=\"token punctuation\">,</span> err\n\t<span class=\"token punctuation\">}</span>\n\tpostingsIndex <span class=\"token operator\">:=</span> toc<span class=\"token punctuation\">.</span>postings<span class=\"token punctuation\">.</span><span class=\"token function\">relativeIndex</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n\tngrams <span class=\"token operator\">:=</span> <span class=\"token keyword\">map</span><span class=\"token punctuation\">[</span>ngram<span class=\"token punctuation\">]</span>simpleSection<span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n\t<span class=\"token keyword\">for</span> i <span class=\"token operator\">:=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> <span class=\"token function\">len</span><span class=\"token punctuation\">(</span>textContent<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">+=</span> ngramEncoding <span class=\"token punctuation\">{</span>\n\t\tj <span class=\"token operator\">:=</span> i <span class=\"token operator\">/</span> ngramEncoding\n\t\tng <span class=\"token operator\">:=</span> <span class=\"token function\">ngram</span><span class=\"token punctuation\">(</span>binary<span class=\"token punctuation\">.</span>BigEndian<span class=\"token punctuation\">.</span><span class=\"token function\">Uint64</span><span class=\"token punctuation\">(</span>textContent<span class=\"token punctuation\">[</span>i <span class=\"token punctuation\">:</span> i<span class=\"token operator\">+</span>ngramEncoding<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\t\tngrams<span class=\"token punctuation\">[</span>ng<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> simpleSection<span class=\"token punctuation\">{</span>\n\t\t\ttoc<span class=\"token punctuation\">.</span>postings<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>off <span class=\"token operator\">+</span> postingsIndex<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n\t\t\tpostingsIndex<span class=\"token punctuation\">[</span>j<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">-</span> postingsIndex<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n\t\t<span class=\"token punctuation\">}</span>\n\t<span class=\"token punctuation\">}</span>\n\n\t<span class=\"token keyword\">return</span> ngrams<span class=\"token punctuation\">,</span> <span class=\"token boolean\">nil</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h2 id=\"Step-2-Implement-a-more-compact-data-structure-for-locating-postings-lists\" style=\"position:relative;\"><a href=\"#Step-2-Implement-a-more-compact-data-structure-for-locating-postings-lists\" aria-label=\"Step 2 Implement a more compact data structure for locating postings lists permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 18 95 120\" height=\"18\" width=\"18\"><path d=\"M53.69,78.7H37.94l-5.85,25H21.74l5.85-25H15.89L18,69.1H29.84l4.65-19.65H23.39l2.1-9.6H36.74l5.7-23.7H52.79l-5.7,23.7H62.84l5.7-23.7H78.89l-5.7,23.7H84.74l-2.4,9.6H70.94L66.29,69.1H77.24l-2.4,9.6H64l-5.85,25H47.84Zm-13.5-9.6H55.94l4.65-19.65H44.84Z\"/></svg></a>Step 2: Implement a more compact data structure for locating postings lists</h2>\n<p>Go maps provide O(1) access times, but they consume a fair amount of memory per entry— roughly 40 bytes each. Since this mapping is taking two-thirds of our memory, it’s worthwhile to implement a more compact data structure for it. There are many different kinds of dynamic mapping data structures, but when all you need is a dense static mapping, it’s hard to beat sorted arrays and binary search. Binary search has logarithmic lookup speeds, but accessing this map is not a bottleneck, so using much less space in exchange for slightly slower lookups is a good tradeoff.</p>\n<p>Note that <code class=\"language-text\">simpleSection.sz</code> is computed by subtracting subsequent values of <code class=\"language-text\">postingsIndex</code>. On disk, the posting lists are written in order of ngram values, but this first implementation uses a map so it’s not possible to subtract the neighboring values. Storing these mappings as two slices instead of a map reduces its memory usage from 15GB to 5GB.</p>\n<div class=\"gatsby-highlight\" data-language=\"go\"><pre class=\"language-go\"><code class=\"language-go\"><span class=\"token comment\">// arrayNgramOffset uses simple linear arrays and binary search for Get()</span>\n<span class=\"token keyword\">type</span> arrayNgramOffset <span class=\"token keyword\">struct</span> <span class=\"token punctuation\">{</span>\n       ngrams <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>ngram\n       <span class=\"token comment\">// offsets is values from simpleSection.off. simpleSection.sz is computed by subtracting adjacent offsets.</span>\n       offsets <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token builtin\">uint32</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h2 id=\"Step-3-Cut-64-bit-ngrams-in-two\" style=\"position:relative;\"><a href=\"#Step-3-Cut-64-bit-ngrams-in-two\" aria-label=\"Step 3 Cut 64 bit ngrams in two permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 18 95 120\" height=\"18\" width=\"18\"><path d=\"M53.69,78.7H37.94l-5.85,25H21.74l5.85-25H15.89L18,69.1H29.84l4.65-19.65H23.39l2.1-9.6H36.74l5.7-23.7H52.79l-5.7,23.7H62.84l5.7-23.7H78.89l-5.7,23.7H84.74l-2.4,9.6H70.94L66.29,69.1H77.24l-2.4,9.6H64l-5.85,25H47.84Zm-13.5-9.6H55.94l4.65-19.65H44.84Z\"/></svg></a>Step 3: Cut 64-bit ngrams in two</h2>\n<p>For <a href=\"https://github.com/sourcegraph/zoekt/commit/2602014e1fafa254900241b6f19b3c4e7da07ced\">slightly more complexity</a>, the 64-bit ngrams can be cut into 32-bit top and bottom pieces. Thanks to how the rune packing works, this is very similar to the top half representing the first character of the trigram, and the bottom half being the second two characters. This reduces memory usage even further to 3.5GB.</p>\n<div class=\"gatsby-highlight\" data-language=\"go\"><pre class=\"language-go\"><code class=\"language-go\"><span class=\"token comment\">// arrayNgramOffset splits ngrams into two 32-bit parts and uses binary search.</span>\n<span class=\"token keyword\">type</span> arrayNgramOffset <span class=\"token keyword\">struct</span> <span class=\"token punctuation\">{</span>\n       <span class=\"token comment\">// tops specify where the bottom halves of ngrams with the 32-bit top half begin.</span>\n       <span class=\"token comment\">// The offset of the next value is used to find where the bottom section ends.</span>\n       tops <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>topOffset\n\n       <span class=\"token comment\">// bots are bottom halves of an ngram, referenced by tops</span>\n       bots <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token builtin\">uint32</span>\n\n       <span class=\"token comment\">// offsets is values from simpleSection.off, simpleSection.sz is computed by subtracting adjacent offsets.</span>\n       offsets <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token builtin\">uint32</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>A three-level <a href=\"https://en.wikipedia.org/wiki/Trie\">trie</a> over the runes of a trigram uses 20% more memory than this simple two-level split, mostly due to the additional overhead from the third level of offsets.</p>\n<h2 id=\"Step-4-Split-ASCII-and-Unicode-trigrams\" style=\"position:relative;\"><a href=\"#Step-4-Split-ASCII-and-Unicode-trigrams\" aria-label=\"Step 4 Split ASCII and Unicode trigrams permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 18 95 120\" height=\"18\" width=\"18\"><path d=\"M53.69,78.7H37.94l-5.85,25H21.74l5.85-25H15.89L18,69.1H29.84l4.65-19.65H23.39l2.1-9.6H36.74l5.7-23.7H52.79l-5.7,23.7H62.84l5.7-23.7H78.89l-5.7,23.7H84.74l-2.4,9.6H70.94L66.29,69.1H77.24l-2.4,9.6H64l-5.85,25H47.84Zm-13.5-9.6H55.94l4.65-19.65H44.84Z\"/></svg></a>Step 4: Split ASCII and Unicode trigrams</h2>\n<p>These trigrams take 64 bits to represent three 21-bit Unicode characters, but most source code and trigrams that we index are 7-bit ASCII. This can be used with a <a href=\"https://github.com/sourcegraph/zoekt/commit/6e5e87c1e07ed9902b6b8716b02f4dd7aeecaff3\">more complex scheme</a> to have two mappings, splitting ASCII trigrams from Unicode ones, reducing the memory used for these offsets from 3.5GB to 2.3GB.</p>\n<h2 id=\"Step-5-Other-metadata-optimizations\" style=\"position:relative;\"><a href=\"#Step-5-Other-metadata-optimizations\" aria-label=\"Step 5 Other metadata optimizations permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 18 95 120\" height=\"18\" width=\"18\"><path d=\"M53.69,78.7H37.94l-5.85,25H21.74l5.85-25H15.89L18,69.1H29.84l4.65-19.65H23.39l2.1-9.6H36.74l5.7-23.7H52.79l-5.7,23.7H62.84l5.7-23.7H78.89l-5.7,23.7H84.74l-2.4,9.6H70.94L66.29,69.1H77.24l-2.4,9.6H64l-5.85,25H47.84Zm-13.5-9.6H55.94l4.65-19.65H44.84Z\"/></svg></a>Step 5: Other metadata optimizations</h2>\n<p>Shrinking the ngram offsets to a fraction of their size means that the heap profiles start to be dominated by other functions that were previously negligible. Some pieces of metadata were changed to be kept on disk or in a compressed form until accessed. Filenames have a trigram index just like file contents, but their postings lists are loaded into memory and decompressed. <a href=\"https://github.com/sourcegraph/zoekt/commit/63b177332c8653ebdc928e23ffdcba9ff4f4a1d1\">Leaving them compressed</a> until needed reduced their memory from 3.3GB to 1.1GB.</p>\n<p>Zoekt stores offsets in its posting lists according to the number of Unicode <strong>runes</strong>, not the number of <strong>bytes</strong>, and they must be converted during searches. To make this faster, the byte offsets for every 100 runes are stored. This scales linearly with the total size of a repository. Since most source code content is ASCII, a simple <a href=\"https://github.com/sourcegraph/zoekt/commit/099907aa573abce45ce534364586ac25a6820a07\">compression scheme</a> reduces this from 2.3GB to 0.2GB by turning offsets like <code class=\"language-text\">{0, 105, 205, 305, 430}</code> into only the points where the one byte per rune assumption didn’t hold: <code class=\"language-text\">{{100, 105}, {400, 430}}</code></p>\n<p>As a nice trivial optimization, if you <a href=\"https://blog.golang.org/slices-intro#TOC_6.\">copy a slice</a> that grew dynamically into a precisely sized one, you don’t waste the unused trailing capacity, which saves another 500MB across our test corpus. Slices grow exponentially when needed in order to make appending to them take constant amortized time, but after it’s done being appended to this excess capacity is no longer necessary.</p>\n<div class=\"gatsby-highlight\" data-language=\"go\"><pre class=\"language-go\"><code class=\"language-go\"><span class=\"token comment\">// shrinkUint32Slice copies slices with excess capacity to precisely sized ones</span>\n<span class=\"token comment\">// to avoid wasting memory. It should be used on slices with long static durations.</span>\n<span class=\"token keyword\">func</span> <span class=\"token function\">shrinkUint32Slice</span><span class=\"token punctuation\">(</span>a <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token builtin\">uint32</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token builtin\">uint32</span> <span class=\"token punctuation\">{</span>\n       <span class=\"token keyword\">if</span> <span class=\"token function\">cap</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span><span class=\"token operator\">-</span><span class=\"token function\">len</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> <span class=\"token number\">32</span> <span class=\"token punctuation\">{</span>\n               <span class=\"token keyword\">return</span> a\n       <span class=\"token punctuation\">}</span>\n       out <span class=\"token operator\">:=</span> <span class=\"token function\">make</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token builtin\">uint32</span><span class=\"token punctuation\">,</span> <span class=\"token function\">len</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n       <span class=\"token function\">copy</span><span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">,</span> a<span class=\"token punctuation\">)</span>\n       <span class=\"token keyword\">return</span> out\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h2 id=\"Results-and-whats-next\" style=\"position:relative;\"><a href=\"#Results-and-whats-next\" aria-label=\"Results and whats next permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 18 95 120\" height=\"18\" width=\"18\"><path d=\"M53.69,78.7H37.94l-5.85,25H21.74l5.85-25H15.89L18,69.1H29.84l4.65-19.65H23.39l2.1-9.6H36.74l5.7-23.7H52.79l-5.7,23.7H62.84l5.7-23.7H78.89l-5.7,23.7H84.74l-2.4,9.6H70.94L66.29,69.1H77.24l-2.4,9.6H64l-5.85,25H47.84Zm-13.5-9.6H55.94l4.65-19.65H44.84Z\"/></svg></a>Results and what’s next</h2>\n<figure>\n  <img src=\"/blog/4GB of live objects after, with all optimizations applied.png\" alt=\"22GB of live objects on one server\" class=\"no-shadow\">\n  <figcaption>4GB of live objects after, with all optimizations applied.</figcaption>\n</figure>\n<p>Putting it all together, the new memory profile looks like this: a 5x reduction overall, which means we can serve search queries for five times more repositories without requiring any more servers. We went from 1400KB of RAM per repo to 310KB with no measurable latency changes.</p>\n<p>In the future, even more of what’s currently loaded into RAM can be placed back onto the disk, using memory mappings to let the OS cache pages as necessary. Larger-scale architectural changes, like having an index cover multiple repositories, or having one large inverted index for each server, will reduce RAM usage even further. These complex changes require more careful planning, coding, and testing than the simple, targeted optimizations described above, but are the best way to escape from the local minima that repeated micro-optimizations can reach.</p>\n<p><em>Look out for Han-Wen Nienhuys, creator of Zoekt, in an upcoming episode of the <a href=\"/podcast\">Sourcegraph podcast!</a></em></p>\n<h3 id=\"More-posts-like-this\" style=\"position:relative;\"><a href=\"#More-posts-like-this\" aria-label=\"More posts like this permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 18 95 120\" height=\"18\" width=\"18\"><path d=\"M53.69,78.7H37.94l-5.85,25H21.74l5.85-25H15.89L18,69.1H29.84l4.65-19.65H23.39l2.1-9.6H36.74l5.7-23.7H52.79l-5.7,23.7H62.84l5.7-23.7H78.89l-5.7,23.7H84.74l-2.4,9.6H70.94L66.29,69.1H77.24l-2.4,9.6H64l-5.85,25H47.84Zm-13.5-9.6H55.94l4.65-19.65H44.84Z\"/></svg></a>More posts like this</h3>\n<ul>\n<li><a href=\"/blog/how-not-to-break-a-search-engine-unglamorous-engineering/\">How not to break a search engine or: What I learned about unglamorous engineering</a></li>\n<li><a href=\"/blog/optimizing-a-code-intel-commit-graph/\">Optimizing a code intelligence commit graph</a></li>\n<li><a href=\"/blog/avoiding-the-pitfalls-of-iteration-based-development/\">Avoiding the pitfalls of iteration-based development, explained in 5 pull requests</a></li>\n</ul>\n<style>\n  figure .no-shadow { box-shadow: none; }\n  .workingtable-highlight td { color: #ffffff; background-color: #005cb9; }\n\n  figcaption {\n    text-align: center;\n    margin-top: -2rem;\n    font-style: italic;\n  }\n</style>"}