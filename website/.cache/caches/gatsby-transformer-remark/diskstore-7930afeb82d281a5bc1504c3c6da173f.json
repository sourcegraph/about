{"expireTime":9007200905229171000,"key":"transformer-remark-markdown-html-7f93b20e455f32b37b0ca289d3cbe72e-gatsby-remark-autolink-headersgatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-unwrap-imagesgatsby-remark-imagesgatsby-remark-smartypants-","val":"<img src=\"https://user-images.githubusercontent.com/3173176/137389515-bc672c66-e7f6-4cbb-9ef9-0e060177c9bf.png\" alt=\"Graphic: Postgres text search, balancing query time and relevancy. Code analysis + Postgres = love\">\n<p>I’ve worked at Sourcegraph for nearly 7 years, and during that time I’ve worked with various search backends, such as Google’s <a href=\"https://github.com/google/zoekt/\">Zoekt</a> (“Fast trigram code search”), Postgres search, and a slew of other homegrown search backends. Outside of Sourcegraph, I <a href=\"https://github.com/slimsag\">also research and develop search engines</a>.</p>\n<p>I enjoy Postgres quite a lot: it’s great software, and the pg_trgm extension for it, which provides trigram search indexing, is something that I love playing around with. In my spare time, I regularly experiment with <a href=\"https://devlog.hexops.com/2021/postgres-regex-search-over-10000-github-repositories\">pushing it to its limits</a>.</p>\n<h2 id=\"What-is-pg_trgm\" style=\"position:relative;\"><a href=\"#What-is-pg_trgm\" aria-label=\"What is pg_trgm permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 18 95 120\" height=\"18\" width=\"18\"><path d=\"M53.69,78.7H37.94l-5.85,25H21.74l5.85-25H15.89L18,69.1H29.84l4.65-19.65H23.39l2.1-9.6H36.74l5.7-23.7H52.79l-5.7,23.7H62.84l5.7-23.7H78.89l-5.7,23.7H84.74l-2.4,9.6H70.94L66.29,69.1H77.24l-2.4,9.6H64l-5.85,25H47.84Zm-13.5-9.6H55.94l4.65-19.65H44.84Z\"/></svg></a>What is pg_trgm?</h2>\n<p><a href=\"https://www.postgresql.org/docs/current/pgtrgm.html\">pg_trgm</a> is an official extension to Postgres. pg_trgm enables trigram indexing and search over Postgres text columns.</p>\n<blockquote>\n<p>A trigram is a group of three consecutive characters taken from a string. We can measure the similarity of two strings by counting the number of trigrams they share. This simple idea turns out to be very effective for measuring the similarity of words in many natural languages.</p>\n</blockquote>\n<p>Trigram indexes are great for implementing text search, and they’re the backbone of Sourcegraph’s indexed search (although we use Zoekt, not Postgres, for reasons I’ll get into below.)</p>\n<p>The difference between pg*trgm (Trigram indexing) and FTS (Full Text Search, tsvector) is that the former is an index over all characters, while the latter is an index over <em>words</em>. <strong>If you can get away with indexing words and only matching whole words (or prefixes of words), FTS / tsvector is usually much faster because it is indexing far less data.</strong> When searching for code, though, we care a lot about punctuation symbols, for example–each character matters.</p>\n<p>One particularly nice property of trigram indexes is that they can partially index regular expression searches–a property code search engines like to utilize:</p>\n<div class=\"gatsby-highlight\" data-language=\"sql\"><pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">SELECT</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">FROM</span> test_trgm <span class=\"token keyword\">WHERE</span> t <span class=\"token operator\">~</span> <span class=\"token string\">'(foo|bar)'</span><span class=\"token punctuation\">;</span></code></pre></div>\n<p>The more trigrams that can be extracted from the regexp’s terms, the more effective the index is. In the worst case (e.g. <code class=\"language-text\">.*</code>) it would result in a full table scan.</p>\n<h2 id=\"Search-result-relevance-in-the-pg_trgm-world\" style=\"position:relative;\"><a href=\"#Search-result-relevance-in-the-pg_trgm-world\" aria-label=\"Search result relevance in the pg_trgm world permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 18 95 120\" height=\"18\" width=\"18\"><path d=\"M53.69,78.7H37.94l-5.85,25H21.74l5.85-25H15.89L18,69.1H29.84l4.65-19.65H23.39l2.1-9.6H36.74l5.7-23.7H52.79l-5.7,23.7H62.84l5.7-23.7H78.89l-5.7,23.7H84.74l-2.4,9.6H70.94L66.29,69.1H77.24l-2.4,9.6H64l-5.85,25H47.84Zm-13.5-9.6H55.94l4.65-19.65H44.84Z\"/></svg></a>Search result relevance in the pg_trgm world</h2>\n<p>Another nice property of Postgres trigram search is the ability to order results by similarity to the actual search terms, i.e. to get relevant results. For example, we can go beyond getting back results that are similar but not relevant to our search terms <code class=\"language-text\">Package json</code>:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">sg=&gt; SELECT label FROM lsif_data_documentation_search_public WHERE label &lt;&lt;% &#39;Package json&#39; LIMIT 10;\n     label\n---------------\n Package main\n Package mocks\n Package lib\n Package main\n Package main\n Package main\n Package main\n Package main\n Package s3\n Package mocks\n(10 rows)</code></pre></div>\n<p>We can instead ask Postgres to count the number of matching trigrams between our <code class=\"language-text\">label</code> text column and our search query terms (<code class=\"language-text\">Package json</code>) and give us an indication of how similar they are. This returns a number between zero and one, where zero is a perfect match and one is a poor match:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">sg=&gt; select label, label &lt;&lt;&lt;-&gt; &#39;Package json&#39; as label_dist from lsif_data_documentation_search_public WHERE label &lt;&lt;% &#39;Package json&#39; ORDER BY label_dist LIMIT 10;\n      label      | label_dist\n-----------------+-------------\n Package json    |           0\n Package p       | 0.111111104\n Package pac     | 0.111111104\n Package page    | 0.111111104\n Package json_v2 |      0.1875\n Package a       |  0.19999999\n Package b       |  0.19999999\n Package c       |  0.19999999\n Package d       |  0.19999999\n Package e       |  0.19999999\n(10 rows)</code></pre></div>\n<p>Using this search, we get better matches that are more relevant to our query terms.</p>\n<h2 id=\"The-problem-performance\" style=\"position:relative;\"><a href=\"#The-problem-performance\" aria-label=\"The problem performance permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 18 95 120\" height=\"18\" width=\"18\"><path d=\"M53.69,78.7H37.94l-5.85,25H21.74l5.85-25H15.89L18,69.1H29.84l4.65-19.65H23.39l2.1-9.6H36.74l5.7-23.7H52.79l-5.7,23.7H62.84l5.7-23.7H78.89l-5.7,23.7H84.74l-2.4,9.6H70.94L66.29,69.1H77.24l-2.4,9.6H64l-5.85,25H47.84Zm-13.5-9.6H55.94l4.65-19.65H44.84Z\"/></svg></a>The problem: performance</h2>\n<p>One major problem with using pg*trgm’s relevancy ordering– i.e. <code class=\"language-text\">ORDER BY</code> with a trigram match distance–is that it often <em>substantially</em> harms query time. We’ve traded our ultra-fast search results, which were often completely irrelevant, for very relevant results suffering from super slow query times:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">sg=&gt; SELECT label FROM lsif_data_documentation_search_public WHERE label &lt;&lt;% &#39;Package json&#39; LIMIT 1;\n    label\n--------------\n Package main\n(1 row)\n\nTime: 83.221 ms</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">sg=&gt; select label, label &lt;&lt;&lt;-&gt; &#39;Package json&#39; as label_dist from lsif_data_documentation_search_public WHERE label &lt;&lt;% &#39;Package json&#39; ORDER BY label_dist LIMIT 1;\n    label     | label_dist\n--------------+------------\n Package json |          0\n(1 row)\n\nTime: 6926.863 ms (00:06.927)</code></pre></div>\n<p>The difference between 80ms and 6.9 <em>seconds</em> is shown on a quite small data set of just 54 MB of text across 1 million rows. With larger data sets, the difference is <em>far worse</em>.</p>\n<p>And that’s where things get tricky: pg*trgm really can’t know how similar our query <code class=\"language-text\">Package json</code> is to potential matches unless it actually calculates that for each match in the trigram index–and there can be <em>many</em> matching rows. For some query terms, you could match nearly all trigrams in the entire index and devolve into a full table scan–super slow!</p>\n<h2 id=\"Why-is-relevance-important-in-code-search\" style=\"position:relative;\"><a href=\"#Why-is-relevance-important-in-code-search\" aria-label=\"Why is relevance important in code search permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 18 95 120\" height=\"18\" width=\"18\"><path d=\"M53.69,78.7H37.94l-5.85,25H21.74l5.85-25H15.89L18,69.1H29.84l4.65-19.65H23.39l2.1-9.6H36.74l5.7-23.7H52.79l-5.7,23.7H62.84l5.7-23.7H78.89l-5.7,23.7H84.74l-2.4,9.6H70.94L66.29,69.1H77.24l-2.4,9.6H64l-5.85,25H47.84Zm-13.5-9.6H55.94l4.65-19.65H44.84Z\"/></svg></a>Why is relevance important in code search?</h2>\n<p>Systems like Google’s <a href=\"https://github.com/google/zoekt/\">Zoekt</a> (“Fast trigram code search”) work around this performance issue by ranking results using <a href=\"https://github.com/google/zoekt/blob/f7d54faa261b31f7258a2d1291531ebd89ce8ee5/doc/design.md#ranking\">various signals at indexing time</a> to order documents in shards so that the more important documents are searched first, also locating a larger number of candidate results and then sorting those candidates to match the query before returning a subset of those candidates. A partial consideration of ranking.</p>\n<p>Sourcegraph does something similar to Zoekt, but we apply some ranking on top at higher level units of code based on things like repo stars and offer <code class=\"language-text\">repo:</code>, <code class=\"language-text\">file:</code>, and more filtering capabilities. In general, most code search systems rely on query-time filtering syntax to work around the issue of relevance being costly. A typical workflow in Sourcegraph looks like:</p>\n<img src=\"https://user-images.githubusercontent.com/3173176/137390361-145c8315-b4c6-4ee9-a45a-223e93f424db.png\" alt=\"Graphic: Sourcegraph search today, a search begins by getting lots of results. These results match your literal query, or regexp query, etc. but you get too many results. There is a lack of relevance. Then you apply advanced filtering, more filtering, etc. to get to a desired result.\">\n<p>If you’ve worked with code search tools like Sourcegraph, Zoekt, OpenGrok before then this workflow can make <em>a lot of sense.</em> There is a great deal of power that comes with the filtering capabilities in these systems. In many situations, the filtering capabilities are better than having a Google-esque “we think this result is most relevant to you” decision being made for you–a decision you cannot change.</p>\n<p>Still, many people who’ve never used such a tool before will search for specific code, such as a repository name, a function name, or a class in hopes of finding that specific code so they can explore it further. In these cases, it would be nice to be able to accurately answer these types of queries. Think of it as the “I’m feeling lucky” of code search:</p>\n<img src=\"https://user-images.githubusercontent.com/3173176/137226418-8b0fbf66-fcf6-42ff-9166-e3d4c9f54351.png\" alt=\"Graphic: Sourcegraph search over API docs, a search begins by locating the best 1-3 results. These are relevant results due to searching over symbols not entire code files, fuzzier so you chuck in what you know and we try to match it, logical so e.g. &#x22;go package net/&#x22; shows all net/ packages. You get desired results right out of the gate.\">\n<h2 id=\"The-need-for-balancing-time-and-result-relevance\" style=\"position:relative;\"><a href=\"#The-need-for-balancing-time-and-result-relevance\" aria-label=\"The need for balancing time and result relevance permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 18 95 120\" height=\"18\" width=\"18\"><path d=\"M53.69,78.7H37.94l-5.85,25H21.74l5.85-25H15.89L18,69.1H29.84l4.65-19.65H23.39l2.1-9.6H36.74l5.7-23.7H52.79l-5.7,23.7H62.84l5.7-23.7H78.89l-5.7,23.7H84.74l-2.4,9.6H70.94L66.29,69.1H77.24l-2.4,9.6H64l-5.85,25H47.84Zm-13.5-9.6H55.94l4.65-19.65H44.84Z\"/></svg></a>The need for balancing time and result relevance</h2>\n<p>As I build this system for Sourcegraph–integrating the code analysis data we have for generating API docs for your code into our search backend–I’ve chosen to use Postgres.\nOne reason why is the effective similarity matching between previously mentioned: it’s perfect for this use case, where we want a user to type in a query like <code class=\"language-text\">github.com/my/repo</code>, or a partial repo name, a Go package name, a function name, or a type signature and get back an “I’m feeling lucky” type result.</p>\n<p>The challenge, as mentioned previously, is that we have to decide between query times being fast or results being relevant. The worst of tradeoffs!</p>\n<p>I’m certainly not the only one facing that–just a bit of Googling will reveal this is a common problem:</p>\n<ul>\n<li><a href=\"https://dba.stackexchange.com/questions/208346/slow-query-times-for-similarity-searches-with-pg-trgm-indices\">“Slow query times for similarity searches with pg_trgm indices”</a></li>\n<li><a href=\"https://dba.stackexchange.com/questions/16437/optimizing-order-by-in-a-full-text-search-query?rq=1\">“Optimizing ORDER BY in a full text search query”</a></li>\n</ul>\n<p>There are lots of things you can do to try improving the performance here, such as reconsidering a GIN vs GIST index, <a href=\"https://stackoverflow.com/a/44853236\">altering work_mem configuration</a> and <a href=\"https://devlog.hexops.com/2021/postgres-regex-search-over-10000-github-repositories#conclusions\">my recommendations here for using pg_trgm</a> such as <a href=\"https://devlog.hexops.com/2021/postgres-regex-search-over-10000-github-repositories#table-splitting\">enabling parallel querying and parallel indexing of Trigram indexes via table splitting</a></p>\n<p>But none of these will fully eliminate the possibility of <code class=\"language-text\">ORDER BY</code> similarity devolving into a slow query. Why does that happen, and can we prevent that?</p>\n<h2 id=\"Trigram-index-poisoning\" style=\"position:relative;\"><a href=\"#Trigram-index-poisoning\" aria-label=\"Trigram index poisoning permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 18 95 120\" height=\"18\" width=\"18\"><path d=\"M53.69,78.7H37.94l-5.85,25H21.74l5.85-25H15.89L18,69.1H29.84l4.65-19.65H23.39l2.1-9.6H36.74l5.7-23.7H52.79l-5.7,23.7H62.84l5.7-23.7H78.89l-5.7,23.7H84.74l-2.4,9.6H70.94L66.29,69.1H77.24l-2.4,9.6H64l-5.85,25H47.84Zm-13.5-9.6H55.94l4.65-19.65H44.84Z\"/></svg></a>Trigram index poisoning</h2>\n<p>The reason <code class=\"language-text\">ORDER BY</code> with trigram similarity ordering can often devolve into a slow query is because of the number of rows Postgres must compare for similarity.</p>\n<p>This usually isn’t all rows in the table, but it can be a significant portion of them. The reason this happens is because of trigram index poisoning.</p>\n<p>Consider this: you have a table of GitHub repository names (or email addresses) with a pg_trgm index for the column. If every row in the table has a common set of trigrams (a shared string of characters):</p>\n<ol start=\"0\">\n<li><strong>github.com/</strong>sourcegraph/sourcegraph</li>\n<li><strong>github.com/</strong>golang/go</li>\n<li><strong>github.com/</strong>kubernetes/kubernetes</li>\n<li>stash.company.com/foo/bar</li>\n<li>…</li>\n</ol>\n<p>A query for <code class=\"language-text\">github.com/foo/bar</code> against such a table will find the first three entries because the shared <code class=\"language-text\">github.com/</code> prefixes are similar. If they’re similar enough to pass your query’s <code class=\"language-text\">WHERE &lt;&lt;% ‘query terms’</code> clause, then all such rows need to have their similarity compared and ordered–even if you plan to just <code class=\"language-text\">LIMIT</code> the result set in the end. This can end up being quite a lot of rows.</p>\n<p>Also, imagine a table of email addresses with a common <code class=\"language-text\">@gmail.com</code> suffix, and then searching for an email <code class=\"language-text\">anything@gmail.com</code>. You can imagine almost all rows being similar enough to need ordering. This is what I mean when I say “trigram index poisoning”: we’ve very nearly rendered our trigram index useless.</p>\n<p>You can avoid trigram index poisoning by ensuring that entries don’t have common/shared substrings, but in practice, trigram index poisoning is hard to avoid and is often just an artifact of using trigram indexes altogether that one must live with and work around.</p>\n<h2 id=\"Limiting-query-time\" style=\"position:relative;\"><a href=\"#Limiting-query-time\" aria-label=\"Limiting query time permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 18 95 120\" height=\"18\" width=\"18\"><path d=\"M53.69,78.7H37.94l-5.85,25H21.74l5.85-25H15.89L18,69.1H29.84l4.65-19.65H23.39l2.1-9.6H36.74l5.7-23.7H52.79l-5.7,23.7H62.84l5.7-23.7H78.89l-5.7,23.7H84.74l-2.4,9.6H70.94L66.29,69.1H77.24l-2.4,9.6H64l-5.85,25H47.84Zm-13.5-9.6H55.94l4.65-19.65H44.84Z\"/></svg></a>Limiting query time</h2>\n<p>One option for preventing queries from taking a long time is to keep our <code class=\"language-text\">ORDER BY</code> similarity–which is expensive–and apply <a href=\"https://blog.crunchydata.com/blog/control-runaway-postgres-queries-with-statement-timeout\">a statement timeout</a>. A statement timeout protects our database against runaway poison-pill queries: If the trigram index finds few enough results to complete within the statement timeout, you get good results. The downside, of course, is that if the statement timeout is hit, you don’t just get worse results–you get <em>no results at all</em>. Bummer.</p>\n<p>What other options do we have?</p>\n<h2 id=\"Choosing-a-similarity-threshold\" style=\"position:relative;\"><a href=\"#Choosing-a-similarity-threshold\" aria-label=\"Choosing a similarity threshold permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 18 95 120\" height=\"18\" width=\"18\"><path d=\"M53.69,78.7H37.94l-5.85,25H21.74l5.85-25H15.89L18,69.1H29.84l4.65-19.65H23.39l2.1-9.6H36.74l5.7-23.7H52.79l-5.7,23.7H62.84l5.7-23.7H78.89l-5.7,23.7H84.74l-2.4,9.6H70.94L66.29,69.1H77.24l-2.4,9.6H64l-5.85,25H47.84Zm-13.5-9.6H55.94l4.65-19.65H44.84Z\"/></svg></a>Choosing a similarity threshold</h2>\n<p>pg_trgm provides the ability for us to replace our <code class=\"language-text\">WHERE &lt;&lt;% ‘query terms’</code> condition, which defaults to a strict word similarity threshold of 0.5, with our own threshold value. In effect, instead of using <code class=\"language-text\">ORDER BY</code> similarity we can just ask Postgres to only give us more similar results–don’t include the others.–his can be much faster because it doesn’t need to sort so many results while still giving good relevance. Swapping the default 0.5 with 0.9 gives us what we’d expect:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">sourcegraph=# select label, label &lt;&lt;&lt;-&gt; &#39;Package json&#39; as label_dist from lsif_data_documentation_search_public WHERE strict_word_similarity(label, &#39;Package json&#39;) &gt; 0.9 LIMIT 10;\n    label     | label_dist\n--------------+------------\n Package json |          0\n(1 row)</code></pre></div>\n<p>But this isn’t a silver bullet either: how do we know which threshold value to choose? There are a couple of problems:</p>\n<p>If results are completely irrelevant (say, under the default threshold of 0.5 similarity) then we’d like to discard the results. That’s easy. But what if we use a similarity threshold of 0.9, or even 1.0,and find no results because our matching threshold is too strict? It’d be nice to fall back to a less strict threshold and give the user some results.\nWith a stricter similarity threshold comes more work for Postgres: although vastly cheaper than ORDER BY similarity, there is always a chance that the terms we’re searching for only has a few similar matching rows.That means pg_trgm is going to spend a lot of time searching for those. Some queries could return in milliseconds and others could take minutes.</p>\n<p>An application-side solution for this might be to execute multiple queries in parallel, each with different similarity thresholds (such as 1.0, 0.9, 0.75, 0.5) and then, after your maximum query time return the results from the “best” threshold, it can cancel any requests that have not yet completed. The benefit of this is that you get pretty relevant results in a reasonable amount of query time; the downside is that you’re issuing 4x queries against your DB.</p>\n<h2 id=\"Whats-the-solution\" style=\"position:relative;\"><a href=\"#Whats-the-solution\" aria-label=\"Whats the solution permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 18 95 120\" height=\"18\" width=\"18\"><path d=\"M53.69,78.7H37.94l-5.85,25H21.74l5.85-25H15.89L18,69.1H29.84l4.65-19.65H23.39l2.1-9.6H36.74l5.7-23.7H52.79l-5.7,23.7H62.84l5.7-23.7H78.89l-5.7,23.7H84.74l-2.4,9.6H70.94L66.29,69.1H77.24l-2.4,9.6H64l-5.85,25H47.84Zm-13.5-9.6H55.94l4.65-19.65H44.84Z\"/></svg></a>What’s the solution?</h2>\n<p>Really, there isn’t a perfect solution.</p>\n<p>The Postgres docs also acknowledge this is a tricky issue: in section <a href=\"https://www.postgresql.org/docs/current/textsearch-controls.html#TEXTSEARCH-RANKING\">“12.3.3. Ranking Search Results”</a> which talks about tsvector search, it says:</p>\n<blockquote>\n<p>Ranking can be expensive since it requires consulting the tsvector of each matching document, which can be I/O bound and therefore slow. Unfortunately, it is almost impossible to avoid since practical queries often result in large numbers of matches.</p>\n</blockquote>\n<p>It would be nice if Postgres had some sort of <code class=\"language-text\">LIMIT BY INTERVAL &#39;00:00:05&#39;</code> functionality to indicate “find as many rows as you can, until you exceed this duration of time”. We could use that functionality in a subquery to find candidates and then <code class=\"language-text\">ORDER BY</code> similarity on the candidate matches that we managed to find in our budgeted amount of query time. But alas, this does not exist. Maybe one day?</p>\n<p>Issuing multiple queries in parallel with different similarity thresholds, as previously mentioned, is not a bad approach. And issuing 4x queries against your DB, while it sounds bad, is in practice (1) cheaper than <code class=\"language-text\">ORDER BY</code> similarity by a long shot and (2) may be handled quite efficiently in terms of in-memory caching because they’re queries against the same table and rows and these queries are often I/O bound.</p>\n<p>If you can get away with whole word (or prefix of words) matching in your use case, you can ditch pg<em>trgm entirely and instead use the FTS / tsvector functionality, which is far faster as it indexes much less data. One should also be mindful of the fact that with that better performance you can locate many more candidate matches to perform an <code class=\"language-text\">ORDER BY</code> on, potentially ending up with better results than if you’d stuck with pg</em>trgm similarity matching. It’s all a game of tradeoffs.</p>\n<h2 id=\"Extensions-that-may-solve-this\" style=\"position:relative;\"><a href=\"#Extensions-that-may-solve-this\" aria-label=\"Extensions that may solve this permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 18 95 120\" height=\"18\" width=\"18\"><path d=\"M53.69,78.7H37.94l-5.85,25H21.74l5.85-25H15.89L18,69.1H29.84l4.65-19.65H23.39l2.1-9.6H36.74l5.7-23.7H52.79l-5.7,23.7H62.84l5.7-23.7H78.89l-5.7,23.7H84.74l-2.4,9.6H70.94L66.29,69.1H77.24l-2.4,9.6H64l-5.85,25H47.84Zm-13.5-9.6H55.94l4.65-19.65H44.84Z\"/></svg></a>Extensions that may solve this</h2>\n<p>(amendment Oct 21, 2021) <a href=\"https://twitter.com/Adrien_nayrat\">Adrien Nayrat</a>, PostgreSQL Expert &#x26; Freelancer, reached out to suggest the Rum index extension may help with this:</p>\n<blockquote>\n<p>Hello,\nI read your article <a href=\"https://about.sourcegraph.com/blog/postgres-text-search-balancing-query-time-and-relevancy/\">https://about.sourcegraph.com/blog/postgres-text-search-balancing-query-time-and-relevancy/</a>\nIndeed, ranking is a known issue.\nDid you consider using Rum indexes? This kind of index will be much larger but are designed to be fast for ranking.\nMore sources on this:</p>\n<ul>\n<li>slides 62-63 <a href=\"https://www.postgresql.eu/events/pgconfeu2018/sessions/session/2116/slides/137/pgconf.eu-2018-fts.pdf\">https://www.postgresql.eu/events/pgconfeu2018/sessions/session/2116/slides/137/pgconf.eu-2018-fts.pdf</a></li>\n<li><a href=\"https://postgrespro.com/blog/pgsql/4262305\">https://postgrespro.com/blog/pgsql/4262305</a></li>\n<li><a href=\"https://github.com/postgrespro/rum\">https://github.com/postgrespro/rum</a></li>\n</ul>\n</blockquote>\n<p>This looks super promising and may well address many of the reasons I / others at Sourcegraph have not used Postgres FTS, so will definitely be investigating this more in the future. One challenge is AWS/GCP Postgres offerrings not supporting this extension currently, though. Thanks for sharing!</p>\n<h2 id=\"Thanks-for-reading\" style=\"position:relative;\"><a href=\"#Thanks-for-reading\" aria-label=\"Thanks for reading permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 18 95 120\" height=\"18\" width=\"18\"><path d=\"M53.69,78.7H37.94l-5.85,25H21.74l5.85-25H15.89L18,69.1H29.84l4.65-19.65H23.39l2.1-9.6H36.74l5.7-23.7H52.79l-5.7,23.7H62.84l5.7-23.7H78.89l-5.7,23.7H84.74l-2.4,9.6H70.94L66.29,69.1H77.24l-2.4,9.6H64l-5.85,25H47.84Zm-13.5-9.6H55.94l4.65-19.65H44.84Z\"/></svg></a>Thanks for reading</h2>\n<p>If you got this far, thanks for reading! The search backend I describe here has not yet made its way into a full production rollout, but will soon. If you’re interested in trying it out, please follow the <a href=\"https://twitter.com/sourcegraph\">Sourcegraph Twitter account</a> for updates.</p>\n<p>Also consider trying my work on generating <a href=\"https://docs.sourcegraph.com/code_intelligence/apidocs\">API docs for your code</a>, which works on any Go repository today!</p>\n<h2 id=\"About-the-author\" style=\"position:relative;\"><a href=\"#About-the-author\" aria-label=\"About the author permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 18 95 120\" height=\"18\" width=\"18\"><path d=\"M53.69,78.7H37.94l-5.85,25H21.74l5.85-25H15.89L18,69.1H29.84l4.65-19.65H23.39l2.1-9.6H36.74l5.7-23.7H52.79l-5.7,23.7H62.84l5.7-23.7H78.89l-5.7,23.7H84.74l-2.4,9.6H70.94L66.29,69.1H77.24l-2.4,9.6H64l-5.85,25H47.84Zm-13.5-9.6H55.94l4.65-19.65H44.84Z\"/></svg></a>About the author</h2>\n<p><a href=\"https://github.com/slimsag\">Stephen Gutekanst</a> is one of Sourcegraph’s earliest engineers, and has authored many parts of Sourcegraph including the src CLI, monitoring architecture, managed instances, and editor extensions to name a few. Stephen has worked with most of Sourcegraph’s largest customers, and enjoys solving the most critical and technically challenging issues users face in our effort to improve the lives of developers everywhere. Outside of Sourcegraph, Stephen <a href=\"https://github.com/slimsag\">researches and develops search engine and video game technology</a>.</p>\n<h2 id=\"More-posts-like-this\" style=\"position:relative;\"><a href=\"#More-posts-like-this\" aria-label=\"More posts like this permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 18 95 120\" height=\"18\" width=\"18\"><path d=\"M53.69,78.7H37.94l-5.85,25H21.74l5.85-25H15.89L18,69.1H29.84l4.65-19.65H23.39l2.1-9.6H36.74l5.7-23.7H52.79l-5.7,23.7H62.84l5.7-23.7H78.89l-5.7,23.7H84.74l-2.4,9.6H70.94L66.29,69.1H77.24l-2.4,9.6H64l-5.85,25H47.84Zm-13.5-9.6H55.94l4.65-19.65H44.84Z\"/></svg></a>More posts like this</h2>\n<ul>\n<li><a href=\"https://about.sourcegraph.com/blog/zoekt-memory-optimizations-for-sourcegraph-cloud/\">A 5x reduction in RAM usage with Zoekt memory optimizations</a></li>\n<li><a href=\"https://about.sourcegraph.com/blog/eliminate-secrets-from-codebase-with-universal-code-search/\">How we used universal code search to eliminate secrets from our codebase</a></li>\n<li><a href=\"https://about.sourcegraph.com/blog/how-not-to-break-a-search-engine-unglamorous-engineering/\">How not to break a search engine or: What I learned about unglamorous engineering</a></li>\n</ul>"}